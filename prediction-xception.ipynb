{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from random import getrandbits\n",
    "from scipy.io import wavfile\n",
    "from subprocess import check_output\n",
    "from keras.models import model_from_json\n",
    "from scipy import signal\n",
    "import librosa\n",
    "\n",
    "def timer():\n",
    "    time_start = [int(time.time())]\n",
    "    time_start_overall = [int(time.time())]\n",
    "\n",
    "    def time_taken():\n",
    "        time_now = int(time.time())\n",
    "        om, os = divmod(time_now - time_start_overall[0], 60)\n",
    "        m, s = divmod(time_now - time_start[0], 60)\n",
    "        time_start[0] = time_now\n",
    "        return ' overall_time: ' + str(om) + 'm' + str(os) + 's' + ' time_from_previous_call: ' + str(m) + 'm' + str(s) + 's'\n",
    "    return time_taken\n",
    "time_taken = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model-pseudo-88-melspec-inception-resnet-v2-1-08-0.99-0.04.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknowns = 'bed bird cat dog eight five four happy house marvin nine one seven sheila six three tree two wow zero'.split()\n",
    "knowns = 'yes no up down left right on off stop go'.split()\n",
    "silence = 'silence'.split()\n",
    "labels = knowns + silence + ['unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fname,label,yes,no,up,down,left,right,on,off,stop,go,silence,unknown\n"
     ]
    }
   ],
   "source": [
    "print('fname,label,' + ','.join(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_melspectrogram(samples):\n",
    "    S = librosa.feature.melspectrogram(samples, sr=sr, n_mels=72, hop_length=223, n_fft=512)\n",
    "    #S = librosa.feature.melspectrogram(samples, sr=sr, n_mels=32)\n",
    "    spec = librosa.power_to_db(S, ref=np.max)\n",
    "    spec = np.repeat(spec[np.newaxis,:,:,np.newaxis], 3, axis=3)\n",
    "    return spec\n",
    "# 150 * 150\n",
    "def get_mel_of_150_150(samples):\n",
    "    S = librosa.feature.melspectrogram(samples, sr=sr, n_mels=150, hop_length=107, n_fft=512)\n",
    "    spec = librosa.power_to_db(S, ref=np.max)\n",
    "    spec = np.repeat(spec[np.newaxis,:,:,np.newaxis], 3, axis=3)\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total files:  158538\n",
      "num_files_read:  5000  overall_time: 1m50s time_from_previous_call: 1m50s\n",
      "num_files_read:  10000  overall_time: 2m43s time_from_previous_call: 0m53s\n",
      "num_files_read:  15000  overall_time: 3m34s time_from_previous_call: 0m51s\n",
      "num_files_read:  20000  overall_time: 4m25s time_from_previous_call: 0m51s\n",
      "num_files_read:  25000  overall_time: 5m15s time_from_previous_call: 0m50s\n",
      "num_files_read:  30000  overall_time: 6m6s time_from_previous_call: 0m51s\n",
      "num_files_read:  35000  overall_time: 6m56s time_from_previous_call: 0m50s\n",
      "num_files_read:  40000  overall_time: 7m48s time_from_previous_call: 0m52s\n",
      "num_files_read:  45000  overall_time: 8m38s time_from_previous_call: 0m50s\n",
      "num_files_read:  50000  overall_time: 9m29s time_from_previous_call: 0m51s\n",
      "num_files_read:  55000  overall_time: 10m21s time_from_previous_call: 0m52s\n",
      "num_files_read:  60000  overall_time: 11m11s time_from_previous_call: 0m50s\n",
      "num_files_read:  65000  overall_time: 12m1s time_from_previous_call: 0m50s\n",
      "num_files_read:  70000  overall_time: 12m52s time_from_previous_call: 0m51s\n",
      "num_files_read:  75000  overall_time: 13m42s time_from_previous_call: 0m50s\n",
      "num_files_read:  80000  overall_time: 14m34s time_from_previous_call: 0m52s\n",
      "num_files_read:  85000  overall_time: 15m25s time_from_previous_call: 0m51s\n",
      "num_files_read:  90000  overall_time: 16m16s time_from_previous_call: 0m51s\n",
      "num_files_read:  95000  overall_time: 17m6s time_from_previous_call: 0m50s\n",
      "num_files_read:  100000  overall_time: 17m56s time_from_previous_call: 0m50s\n",
      "num_files_read:  105000  overall_time: 18m47s time_from_previous_call: 0m51s\n",
      "num_files_read:  110000  overall_time: 19m38s time_from_previous_call: 0m51s\n",
      "num_files_read:  115000  overall_time: 20m28s time_from_previous_call: 0m50s\n",
      "num_files_read:  120000  overall_time: 21m19s time_from_previous_call: 0m51s\n",
      "num_files_read:  125000  overall_time: 22m10s time_from_previous_call: 0m51s\n",
      "num_files_read:  130000  overall_time: 23m0s time_from_previous_call: 0m50s\n",
      "num_files_read:  135000  overall_time: 23m51s time_from_previous_call: 0m51s\n",
      "num_files_read:  140000  overall_time: 24m42s time_from_previous_call: 0m51s\n",
      "num_files_read:  145000  overall_time: 25m32s time_from_previous_call: 0m50s\n",
      "num_files_read:  150000  overall_time: 26m23s time_from_previous_call: 0m51s\n",
      "num_files_read:  155000  overall_time: 27m14s time_from_previous_call: 0m51s\n",
      "done  overall_time: 28m13s time_from_previous_call: 0m59s\n"
     ]
    }
   ],
   "source": [
    "test_dir = '../test/audio/'\n",
    "file_names = []\n",
    "for filename in os.listdir(test_dir):\n",
    "    file_names.append(filename)\n",
    "total_files = len(file_names)\n",
    "print('total files: ', total_files)\n",
    "num_files_read = 0\n",
    "idx = 0\n",
    "nprint = 5000\n",
    "sr = 16000\n",
    "batch_size = 64\n",
    "X = np.random.randn(nprint, 150, 150, 3)\n",
    "f1 = open('model-pseudo-88-melspec-inception-resnet-v2-1-08-0.99-0.04.h5-prediction.csv', 'w')\n",
    "f2 = open('model-pseudo-88-melspec-inception-resnet-v2-1-08-0.99-0.04.h5-prediction-detailed.csv', 'w')\n",
    "f1.write('fname,label\\n')\n",
    "files = []\n",
    "for filename in file_names:\n",
    "    files.append(filename)\n",
    "    samples, _ = librosa.load(test_dir + filename, sr=sr)\n",
    "    spec = get_mel_of_150_150(samples)\n",
    "    X[idx, :, :] = spec\n",
    "    num_files_read += 1\n",
    "    idx += 1\n",
    "    if num_files_read % nprint == 0:\n",
    "        print('num_files_read: ', num_files_read, time_taken())\n",
    "        pred = model.predict(X, batch_size=batch_size, verbose=0)\n",
    "        predictions = np.argmax(pred, axis=1)\n",
    "        for i in range(len(predictions)):\n",
    "            label = labels[predictions[i]]\n",
    "            f1.write('{},{}\\n'.format(files[i], label))\n",
    "            f2.write(files[i] + ',' + label + ',' + str(pred[i][predictions[i]]) + ',' + ','.join([str(x) for x in pred[i]]) + '\\n')\n",
    "        files = []\n",
    "        if (total_files - num_files_read < nprint):\n",
    "            X = np.random.randn(total_files - num_files_read, 150, 150, 3)\n",
    "        idx = 0\n",
    "if len(files):\n",
    "    pred = model.predict(X, batch_size=batch_size, verbose=0)\n",
    "    predictions = np.argmax(pred, axis=1)\n",
    "    for i in range(len(predictions)):\n",
    "        label = labels[predictions[i]]\n",
    "        f1.write('{},{}\\n'.format(files[i], label))\n",
    "        f2.write(files[i] + ',' + label + ',' + str(pred[i][predictions[i]]) + ',' + ','.join([str(x) for x in pred[i]]) + '\\n')\n",
    "f1.close()\n",
    "f2.close()\n",
    "print('done', time_taken())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
