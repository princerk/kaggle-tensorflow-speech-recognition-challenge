{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np # linear algebra\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, Convolution2D, Activation\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import os\n",
    "import random\n",
    "from scipy.io import wavfile\n",
    "from subprocess import check_output\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import acoustics\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import random\n",
    "\n",
    "def timer():\n",
    "    time_start = [int(time.time())]\n",
    "    time_start_overall = [int(time.time())]\n",
    "\n",
    "    def time_taken():\n",
    "        time_now = int(time.time())\n",
    "        om, os = divmod(time_now - time_start_overall[0], 60)\n",
    "        m, s = divmod(time_now - time_start[0], 60)\n",
    "        time_start[0] = time_now\n",
    "        return ' overall_time: ' + str(om) + 'm' + str(os) + 's' + ' time_from_previous_call: ' + str(m) + 'm' + str(s) + 's'\n",
    "    return time_taken\n",
    "time_taken = timer()\n",
    "\n",
    "sr = 16000\n",
    "\n",
    "unknowns = 'bed bird cat dog eight five four happy house marvin nine one seven sheila six three tree two wow zero'.split()\n",
    "knowns = 'yes no up down left right on off stop go'.split()\n",
    "silence = 'silence'.split()\n",
    "labels = knowns + silence + ['unknown'] \n",
    "num_classes = len(labels)\n",
    "\n",
    "LABEL_TO_FILE_NAMES = {}\n",
    "VALIDATION_LABEL_TO_FILE_NAMES = {}\n",
    "TRAIN_LABEL_TO_FILE_NAMES = {}\n",
    "FILE_TO_LABEL = {}\n",
    "with open('train-88.csv') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        line = line.split(',')\n",
    "        LABEL_TO_FILE_NAMES.setdefault(line[1], [])\n",
    "        LABEL_TO_FILE_NAMES[line[1]].append(line[0])\n",
    "        TRAIN_LABEL_TO_FILE_NAMES.setdefault(line[1], [])\n",
    "        TRAIN_LABEL_TO_FILE_NAMES[line[1]].append(line[0])\n",
    "        FILE_TO_LABEL[line[0]] = line[1]\n",
    "with open('validation-88.csv') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        line = line.split(',')\n",
    "        LABEL_TO_FILE_NAMES.setdefault(line[1], [])\n",
    "        LABEL_TO_FILE_NAMES[line[1]].append(line[0])\n",
    "        VALIDATION_LABEL_TO_FILE_NAMES.setdefault(line[1], [])\n",
    "        VALIDATION_LABEL_TO_FILE_NAMES[line[1]].append(line[0])\n",
    "        FILE_TO_LABEL[line[0]] = line[1]\n",
    "\n",
    "\n",
    "def file_to_sample(filename):\n",
    "    samples, _ = librosa.load(filename, sr=sr)\n",
    "    return samples\n",
    "    \n",
    "\n",
    "UNCOLORED_NOISES = []\n",
    "UNCOLORED_NOISES += librosa.load('../train/audio/_background_noise_/doing_the_dishes.wav', sr=sr)[0].tolist()\n",
    "UNCOLORED_NOISES += librosa.load('../train/audio/_background_noise_/dude_miaowing.wav', sr=sr)[0].tolist()\n",
    "UNCOLORED_NOISES += librosa.load('../train/audio/_background_noise_/exercise_bike.wav', sr=sr)[0].tolist()\n",
    "UNCOLORED_NOISES += librosa.load('../train/audio/_background_noise_/running_tap.wav', sr=sr)[0].tolist()\n",
    "\n",
    "\n",
    "def get_silence():\n",
    "    choice = np.random.choice([0, 1, 2, 4], p=[0.01, 0.10, 0.70, 0.19])\n",
    "    if choice == 0:\n",
    "        return np.zeros((16000))\n",
    "    elif choice == 1:\n",
    "        idx = random.randint(0, len(UNCOLORED_NOISES) - sr)\n",
    "        return np.array(UNCOLORED_NOISES[idx:idx+sr], dtype=np.float32)\n",
    "    elif choice == 3:\n",
    "        return np.array(acoustics.generator.noise(16000, color=np.random.choice(['pink', 'white']))/3, np.float32)\n",
    "    else:\n",
    "        random_silence_file = np.random.choice(LABEL_TO_FILE_NAMES['silence'])\n",
    "        return file_to_sample(random_silence_file)\n",
    "\n",
    "def pad_zeros(samples):\n",
    "    if len(samples) < sr:\n",
    "        diff = sr - len(samples)\n",
    "        diff_div = diff // 2\n",
    "        samples = np.lib.pad(samples, (diff_div, diff - diff_div), 'constant', constant_values = (0, 0))\n",
    "    return samples\n",
    "\n",
    "def pitch_shift(samples, sr=sr):\n",
    "    return librosa.effects.pitch_shift(samples, sr=sr, n_steps=random.randint(1, 5))\n",
    "\n",
    "def get_shuffled_XY(X, Y):\n",
    "    m = X.shape[0]\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "    return shuffled_X, shuffled_Y\n",
    "\n",
    "def time_shift(arr):\n",
    "    num = np.random.uniform(0, 0.2) * len(arr)\n",
    "    num = int(num)\n",
    "    result = np.empty_like(arr)\n",
    "    if num > 0:\n",
    "        result[:num] = 0\n",
    "        result[num:] = arr[:-num]\n",
    "    elif num < 0:\n",
    "        result[num:] = 0\n",
    "        result[:num] = arr[-num:]\n",
    "    else:\n",
    "        result = arr\n",
    "    return np.array(result)\n",
    "        \n",
    "def flip_transform(wave):\n",
    "    if np.random.choice([0, 1]):\n",
    "        return -wave\n",
    "\n",
    "def noise_mix(wave):\n",
    "    noise = get_silence()\n",
    "    noise_limit = random.uniform(0, 0.1)\n",
    "    wave = (1 - noise_limit) * wave + noise_limit * noise\n",
    "    return wave\n",
    "\n",
    "# 72 * 72\n",
    "def get_melspectrogram(samples):\n",
    "    S = librosa.feature.melspectrogram(samples, sr=sr, n_mels=72, hop_length=223, n_fft=512)\n",
    "    spec = librosa.power_to_db(S, ref=np.max)\n",
    "    spec = np.repeat(spec[np.newaxis,:,:,np.newaxis], 3, axis=3)\n",
    "    return spec\n",
    "\n",
    "# 150 * 150\n",
    "def get_mel_of_150_150(samples):\n",
    "    S = librosa.feature.melspectrogram(samples, sr=sr, n_mels=150, hop_length=107, n_fft=512)\n",
    "    spec = librosa.power_to_db(S, ref=np.max)\n",
    "    spec = np.repeat(spec[np.newaxis,:,:,np.newaxis], 3, axis=3)\n",
    "    return spec\n",
    "\n",
    "# 197 * 161\n",
    "def log_specgram(audio, sample_rate=16000, window_size=20,\n",
    "                 step_size=15, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    spec = np.log(spec.T.astype(np.float32) + eps)\n",
    "    return np.repeat(spec[np.newaxis,:,:,np.newaxis], 3, axis=3)\n",
    "\n",
    "def get_transformed_samples(samples):\n",
    "    samples = pad_zeros(samples)\n",
    "    samples = time_shift(samples)\n",
    "    samples = noise_mix(samples)\n",
    "    if np.random.choice([0, 1]):\n",
    "        samples = -samples\n",
    "    stdx = np.std(samples)\n",
    "    if stdx:\n",
    "        sampels = samples / stdx\n",
    "    #samples = flip_transform(samples)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'silence', 'unknown']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing train label to filename lengths\n",
      "no 6248\n",
      "up 5944\n",
      "right 6811\n",
      "down 5355\n",
      "off 6456\n",
      "go 5331\n",
      "on 6561\n",
      "yes 6221\n",
      "unknown 70315\n",
      "stop 6733\n",
      "left 6552\n",
      "silence 6591\n",
      "printing validation label to filename lengths\n",
      "no 694\n",
      "up 660\n",
      "right 756\n",
      "down 594\n",
      "off 717\n",
      "go 592\n",
      "on 729\n",
      "yes 691\n",
      "unknown 7812\n",
      "stop 748\n",
      "left 728\n",
      "silence 732\n"
     ]
    }
   ],
   "source": [
    "print('printing train label to filename lengths')\n",
    "for label, filenames in TRAIN_LABEL_TO_FILE_NAMES.items():\n",
    "    print(label, len(filenames))\n",
    "print('printing validation label to filename lengths')\n",
    "for label, filenames in VALIDATION_LABEL_TO_FILE_NAMES.items():\n",
    "    print(label, len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " overall_time: 0m23s time_from_previous_call: 0m23s\n"
     ]
    }
   ],
   "source": [
    "print(time_taken())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "def validation_data_generator():\n",
    "    XV = np.zeros((batch_size, 150, 150, 3))\n",
    "    YV = np.zeros((batch_size, num_classes))\n",
    "    while True:\n",
    "        for idx in range(batch_size):\n",
    "            random_label = np.random.choice(labels)\n",
    "            if random_label == 'silence':\n",
    "                samples = get_silence()\n",
    "            else:\n",
    "                random_filename = np.random.choice(VALIDATION_LABEL_TO_FILE_NAMES[random_label])\n",
    "                samples = file_to_sample(random_filename)\n",
    "                samples = get_transformed_samples(samples)\n",
    "            spec = get_mel_of_150_150(samples)\n",
    "            XV[idx, :, :] = spec\n",
    "            this_Y = [labels.index(random_label)]\n",
    "            this_Y = keras.utils.to_categorical(np.array(this_Y).astype(np.float32), num_classes)\n",
    "            YV[idx, :] = this_Y\n",
    "        yield XV, YV\n",
    "\n",
    "def train_data_generator():\n",
    "    XT = np.zeros((batch_size, 150, 150, 3))\n",
    "    YT = np.zeros((batch_size, num_classes))\n",
    "    while True:\n",
    "        for idx in range(batch_size):\n",
    "            random_label = np.random.choice(labels)\n",
    "            if random_label == 'silence':\n",
    "                samples = get_silence()\n",
    "            else:\n",
    "                random_filename = np.random.choice(TRAIN_LABEL_TO_FILE_NAMES[random_label])\n",
    "                samples = file_to_sample(random_filename)\n",
    "                samples = get_transformed_samples(samples)\n",
    "            spec = get_mel_of_150_150(samples)\n",
    "            XT[idx, :, :] = spec\n",
    "            this_Y = [labels.index(random_label)]\n",
    "            this_Y = keras.utils.to_categorical(np.array(this_Y).astype(np.float32), num_classes)\n",
    "            YT[idx, :] = this_Y\n",
    "        yield XT, YT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.5982 - acc: 0.8105Epoch 00001: val_acc improved from -inf to 0.77695, saving model to model-pseudo-88-melspec-inception-resnet-v2-0-01-0.78-0.72.h5\n",
      "200/200 [==============================] - 567s 3s/step - loss: 0.5963 - acc: 0.8111 - val_loss: 0.7178 - val_acc: 0.7770\n",
      "Epoch 2/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.3038 - acc: 0.9196Epoch 00002: val_acc improved from 0.77695 to 0.90234, saving model to model-pseudo-88-melspec-inception-resnet-v2-0-02-0.90-0.34.h5\n",
      "200/200 [==============================] - 364s 2s/step - loss: 0.3036 - acc: 0.9197 - val_loss: 0.3372 - val_acc: 0.9023\n",
      "Epoch 3/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.2515 - acc: 0.9395Epoch 00003: val_acc improved from 0.90234 to 0.90977, saving model to model-pseudo-88-melspec-inception-resnet-v2-0-03-0.91-0.30.h5\n",
      "200/200 [==============================] - 355s 2s/step - loss: 0.2516 - acc: 0.9396 - val_loss: 0.2972 - val_acc: 0.9098\n",
      "Epoch 4/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.2270 - acc: 0.9459Epoch 00004: val_acc did not improve\n",
      "200/200 [==============================] - 350s 2s/step - loss: 0.2263 - acc: 0.9461 - val_loss: 0.4062 - val_acc: 0.8883\n",
      "Epoch 5/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.2133 - acc: 0.9494Epoch 00005: val_acc improved from 0.90977 to 0.93125, saving model to model-pseudo-88-melspec-inception-resnet-v2-0-05-0.93-0.27.h5\n",
      "200/200 [==============================] - 348s 2s/step - loss: 0.2130 - acc: 0.9495 - val_loss: 0.2654 - val_acc: 0.9313\n",
      "Epoch 6/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1862 - acc: 0.9569Epoch 00006: val_acc did not improve\n",
      "200/200 [==============================] - 346s 2s/step - loss: 0.1864 - acc: 0.9569 - val_loss: 0.3429 - val_acc: 0.9023\n",
      "Epoch 7/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1787 - acc: 0.9596Epoch 00007: val_acc improved from 0.93125 to 0.94141, saving model to model-pseudo-88-melspec-inception-resnet-v2-0-07-0.94-0.23.h5\n",
      "200/200 [==============================] - 342s 2s/step - loss: 0.1785 - acc: 0.9596 - val_loss: 0.2275 - val_acc: 0.9414\n",
      "Epoch 8/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1799 - acc: 0.9594Epoch 00008: val_acc did not improve\n",
      "200/200 [==============================] - 338s 2s/step - loss: 0.1794 - acc: 0.9595 - val_loss: 0.2485 - val_acc: 0.9277\n",
      "Epoch 9/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1626 - acc: 0.9650Epoch 00009: val_acc improved from 0.94141 to 0.95391, saving model to model-pseudo-88-melspec-inception-resnet-v2-0-09-0.95-0.20.h5\n",
      "200/200 [==============================] - 337s 2s/step - loss: 0.1626 - acc: 0.9650 - val_loss: 0.1965 - val_acc: 0.9539\n",
      "Epoch 10/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1737 - acc: 0.9631Epoch 00010: val_acc did not improve\n",
      "200/200 [==============================] - 341s 2s/step - loss: 0.1737 - acc: 0.9630 - val_loss: 0.1922 - val_acc: 0.9437\n",
      "Epoch 11/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1713 - acc: 0.9628Epoch 00011: val_acc did not improve\n",
      "200/200 [==============================] - 333s 2s/step - loss: 0.1714 - acc: 0.9627 - val_loss: 0.2721 - val_acc: 0.9234\n",
      "Epoch 12/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1614 - acc: 0.9638Epoch 00012: val_acc did not improve\n",
      "200/200 [==============================] - 329s 2s/step - loss: 0.1613 - acc: 0.9639 - val_loss: 0.4366 - val_acc: 0.8758\n",
      "Epoch 13/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1615 - acc: 0.9660Epoch 00013: val_acc did not improve\n",
      "200/200 [==============================] - 334s 2s/step - loss: 0.1613 - acc: 0.9661 - val_loss: 0.3585 - val_acc: 0.8996\n",
      "Epoch 14/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1497 - acc: 0.9680Epoch 00014: val_acc did not improve\n",
      "200/200 [==============================] - 328s 2s/step - loss: 0.1503 - acc: 0.9678 - val_loss: 0.3147 - val_acc: 0.9090\n",
      "Epoch 15/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1536 - acc: 0.9673Epoch 00015: val_acc did not improve\n",
      "200/200 [==============================] - 332s 2s/step - loss: 0.1536 - acc: 0.9673 - val_loss: 0.1872 - val_acc: 0.9531\n",
      "Epoch 16/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1423 - acc: 0.9695Epoch 00016: val_acc did not improve\n",
      "200/200 [==============================] - 331s 2s/step - loss: 0.1422 - acc: 0.9695 - val_loss: 0.2551 - val_acc: 0.9262\n",
      "Epoch 17/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1424 - acc: 0.9701Epoch 00017: val_acc did not improve\n",
      "200/200 [==============================] - 335s 2s/step - loss: 0.1420 - acc: 0.9701 - val_loss: 0.2166 - val_acc: 0.9426\n",
      "Epoch 18/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1474 - acc: 0.9703Epoch 00018: val_acc improved from 0.95391 to 0.96133, saving model to model-pseudo-88-melspec-inception-resnet-v2-0-18-0.96-0.16.h5\n",
      "200/200 [==============================] - 330s 2s/step - loss: 0.1477 - acc: 0.9702 - val_loss: 0.1592 - val_acc: 0.9613\n",
      "Epoch 19/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1423 - acc: 0.9694Epoch 00019: val_acc did not improve\n",
      "200/200 [==============================] - 328s 2s/step - loss: 0.1424 - acc: 0.9693 - val_loss: 0.3152 - val_acc: 0.9129\n",
      "Epoch 20/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1527 - acc: 0.9695Epoch 00020: val_acc did not improve\n",
      "200/200 [==============================] - 333s 2s/step - loss: 0.1533 - acc: 0.9694 - val_loss: 0.3034 - val_acc: 0.9090\n",
      "Epoch 21/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1338 - acc: 0.9723Epoch 00021: val_acc did not improve\n",
      "200/200 [==============================] - 327s 2s/step - loss: 0.1338 - acc: 0.9724 - val_loss: 0.1699 - val_acc: 0.9563\n",
      "Epoch 22/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1393 - acc: 0.9720Epoch 00022: val_acc improved from 0.96133 to 0.96172, saving model to model-pseudo-88-melspec-inception-resnet-v2-0-22-0.96-0.16.h5\n",
      "200/200 [==============================] - 328s 2s/step - loss: 0.1395 - acc: 0.9720 - val_loss: 0.1568 - val_acc: 0.9617\n",
      "Epoch 23/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1393 - acc: 0.9721Epoch 00023: val_acc did not improve\n",
      "200/200 [==============================] - 331s 2s/step - loss: 0.1394 - acc: 0.9721 - val_loss: 0.2245 - val_acc: 0.9418\n",
      "Epoch 24/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1343 - acc: 0.9736Epoch 00024: val_acc improved from 0.96172 to 0.96211, saving model to model-pseudo-88-melspec-inception-resnet-v2-0-24-0.96-0.17.h5\n",
      "200/200 [==============================] - 332s 2s/step - loss: 0.1346 - acc: 0.9736 - val_loss: 0.1709 - val_acc: 0.9621\n",
      "Epoch 25/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1385 - acc: 0.9711Epoch 00025: val_acc improved from 0.96211 to 0.96328, saving model to model-pseudo-88-melspec-inception-resnet-v2-0-25-0.96-0.16.h5\n",
      "200/200 [==============================] - 326s 2s/step - loss: 0.1386 - acc: 0.9711 - val_loss: 0.1591 - val_acc: 0.9633\n",
      "Epoch 26/200\n",
      "140/200 [====================>.........] - ETA: 1:22 - loss: 0.1377 - acc: 0.9727"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "model = keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=True, weights=None, input_tensor=None, input_shape=None, pooling=None, classes=num_classes)\n",
    "#model = keras.applications.xception.Xception(include_top=True, weights=None, input_tensor=None, input_shape=None, pooling=None, classes=num_classes)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "#model = load_model('model-xception-0-19-0.98-0.08.h5')\n",
    "checkpoint = ModelCheckpoint('model-pseudo-88-melspec-inception-resnet-v2-0-{epoch:02d}-{val_acc:.2f}-{val_loss:.2f}.h5',\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             mode='max')\n",
    "earlystopping = EarlyStopping(monitor='val_acc', patience=5)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=1e-8, verbose=1)\n",
    "callback_list = [checkpoint, reduce_lr]\n",
    "\n",
    "train_generator = train_data_generator()\n",
    "validation_generator = validation_data_generator()\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=200, \n",
    "                    epochs=epochs, \n",
    "                    callbacks=callback_list,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=20,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time_taken())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
