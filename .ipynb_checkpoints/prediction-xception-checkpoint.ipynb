{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from random import getrandbits\n",
    "from scipy.io import wavfile\n",
    "from subprocess import check_output\n",
    "from keras.models import model_from_json\n",
    "from scipy import signal\n",
    "import librosa\n",
    "import u\n",
    "time_taken = u.timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model-xception-resumed2-02-0.97-0.12.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknowns = 'bed bird cat dog eight five four happy house marvin nine one seven sheila six three tree two wow zero'.split()\n",
    "knowns = 'yes no up down left right on off stop go'.split()\n",
    "silence = 'silence'.split()\n",
    "labels = knowns + silence + ['unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fname,label,yes,no,up,down,left,right,on,off,stop,go,silence,unknown\n"
     ]
    }
   ],
   "source": [
    "print('fname,label,' + ','.join(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_melspectrogram(samples):\n",
    "    S = librosa.feature.melspectrogram(samples, sr=sr, n_mels=72, hop_length=223, n_fft=512)\n",
    "    #S = librosa.feature.melspectrogram(samples, sr=sr, n_mels=32)\n",
    "    spec = librosa.power_to_db(S, ref=np.max)\n",
    "    spec = np.repeat(spec[np.newaxis,:,:,np.newaxis], 3, axis=3)\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total files:  158538\n",
      "num_files_read:  5000  overall_time: 0m44s time_from_previous_call: 0m44s\n",
      "num_files_read:  10000  overall_time: 1m9s time_from_previous_call: 0m25s\n",
      "num_files_read:  15000  overall_time: 1m33s time_from_previous_call: 0m24s\n",
      "num_files_read:  20000  overall_time: 1m57s time_from_previous_call: 0m24s\n",
      "num_files_read:  25000  overall_time: 2m21s time_from_previous_call: 0m24s\n",
      "num_files_read:  30000  overall_time: 2m44s time_from_previous_call: 0m23s\n",
      "num_files_read:  35000  overall_time: 3m8s time_from_previous_call: 0m24s\n",
      "num_files_read:  40000  overall_time: 3m32s time_from_previous_call: 0m24s\n",
      "num_files_read:  45000  overall_time: 3m55s time_from_previous_call: 0m23s\n",
      "num_files_read:  50000  overall_time: 4m19s time_from_previous_call: 0m24s\n",
      "num_files_read:  55000  overall_time: 4m43s time_from_previous_call: 0m24s\n",
      "num_files_read:  60000  overall_time: 5m6s time_from_previous_call: 0m23s\n",
      "num_files_read:  65000  overall_time: 5m30s time_from_previous_call: 0m24s\n",
      "num_files_read:  70000  overall_time: 5m54s time_from_previous_call: 0m24s\n",
      "num_files_read:  75000  overall_time: 6m17s time_from_previous_call: 0m23s\n",
      "num_files_read:  80000  overall_time: 6m41s time_from_previous_call: 0m24s\n",
      "num_files_read:  85000  overall_time: 7m4s time_from_previous_call: 0m23s\n",
      "num_files_read:  90000  overall_time: 7m28s time_from_previous_call: 0m24s\n",
      "num_files_read:  95000  overall_time: 7m51s time_from_previous_call: 0m23s\n",
      "num_files_read:  100000  overall_time: 8m15s time_from_previous_call: 0m24s\n",
      "num_files_read:  105000  overall_time: 8m38s time_from_previous_call: 0m23s\n",
      "num_files_read:  110000  overall_time: 9m2s time_from_previous_call: 0m24s\n",
      "num_files_read:  115000  overall_time: 9m26s time_from_previous_call: 0m24s\n",
      "num_files_read:  120000  overall_time: 9m49s time_from_previous_call: 0m23s\n",
      "num_files_read:  125000  overall_time: 10m13s time_from_previous_call: 0m24s\n",
      "num_files_read:  130000  overall_time: 10m36s time_from_previous_call: 0m23s\n",
      "num_files_read:  135000  overall_time: 11m0s time_from_previous_call: 0m24s\n",
      "num_files_read:  140000  overall_time: 11m24s time_from_previous_call: 0m24s\n",
      "num_files_read:  145000  overall_time: 11m47s time_from_previous_call: 0m23s\n",
      "num_files_read:  150000  overall_time: 12m11s time_from_previous_call: 0m24s\n",
      "num_files_read:  155000  overall_time: 12m34s time_from_previous_call: 0m23s\n",
      "done  overall_time: 12m56s time_from_previous_call: 0m22s\n"
     ]
    }
   ],
   "source": [
    "test_dir = '../test/audio/'\n",
    "file_names = []\n",
    "for filename in os.listdir(test_dir):\n",
    "    file_names.append(filename)\n",
    "total_files = len(file_names)\n",
    "print('total files: ', total_files)\n",
    "num_files_read = 0\n",
    "idx = 0\n",
    "nprint = 5000\n",
    "sr = 16000\n",
    "batch_size = 64\n",
    "X = np.random.randn(nprint, 72, 72, 3)\n",
    "f1 = open('model-xception-resumed2-02-0.97-0.12.h5-prediction.csv', 'w')\n",
    "f2 = open('model-xception-resumed2-02-0.97-0.12.h5-prediction-detailed.csv', 'w')\n",
    "f1.write('fname,label\\n')\n",
    "f2.write('fname,label,max_prob,' + ','.join(labels) + '\\n')\n",
    "files = []\n",
    "for filename in file_names:\n",
    "    files.append(filename)\n",
    "    samples, _ = librosa.load(test_dir + filename, sr=sr)\n",
    "    spec = get_melspectrogram(samples)\n",
    "    X[idx, :, :] = spec\n",
    "    num_files_read += 1\n",
    "    idx += 1\n",
    "    if num_files_read % nprint == 0:\n",
    "        print('num_files_read: ', num_files_read, time_taken())\n",
    "        pred = model.predict(X, batch_size=batch_size, verbose=0)\n",
    "        predictions = np.argmax(pred, axis=1)\n",
    "        for i in range(len(predictions)):\n",
    "            label = labels[predictions[i]]\n",
    "            f1.write('{},{}\\n'.format(files[i], label))\n",
    "            f2.write(files[i] + ',' + label + ',' + str(pred[i][predictions[i]]) + ',' + ','.join([str(x) for x in pred[i]]) + '\\n')\n",
    "        files = []\n",
    "        if (total_files - num_files_read < nprint):\n",
    "            X = np.random.randn(total_files - num_files_read, 72, 72, 3)\n",
    "        idx = 0\n",
    "if len(files):\n",
    "    pred = model.predict(X, batch_size=batch_size, verbose=0)\n",
    "    predictions = np.argmax(pred, axis=1)\n",
    "    for i in range(len(predictions)):\n",
    "        label = labels[predictions[i]]\n",
    "        f1.write('{},{}\\n'.format(files[i], label))\n",
    "        f2.write(files[i] + ',' + label + ',' + str(pred[i][predictions[i]]) + ',' + ','.join([str(x) for x in pred[i]]) + '\\n')\n",
    "f1.close()\n",
    "f2.close()\n",
    "print('done', time_taken())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
