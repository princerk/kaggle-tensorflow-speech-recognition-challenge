{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np # linear algebra\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, Convolution2D, Activation\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import os\n",
    "import random\n",
    "from scipy.io import wavfile\n",
    "from subprocess import check_output\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import acoustics\n",
    "from data_augment import augment_data\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000  overall_time: 0m2s time_from_previous_call: 0m2s\n",
      "10000  overall_time: 0m4s time_from_previous_call: 0m2s\n",
      "15000  overall_time: 0m6s time_from_previous_call: 0m2s\n",
      "20000  overall_time: 0m8s time_from_previous_call: 0m2s\n",
      "25000  overall_time: 0m9s time_from_previous_call: 0m1s\n",
      "30000  overall_time: 0m11s time_from_previous_call: 0m2s\n",
      "35000  overall_time: 0m13s time_from_previous_call: 0m2s\n",
      "40000  overall_time: 0m15s time_from_previous_call: 0m2s\n",
      "45000  overall_time: 0m17s time_from_previous_call: 0m2s\n",
      "50000  overall_time: 0m19s time_from_previous_call: 0m2s\n",
      "55000  overall_time: 0m21s time_from_previous_call: 0m2s\n",
      "60000  overall_time: 0m23s time_from_previous_call: 0m2s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import random\n",
    "\n",
    "def timer():\n",
    "    time_start = [int(time.time())]\n",
    "    time_start_overall = [int(time.time())]\n",
    "\n",
    "    def time_taken():\n",
    "        time_now = int(time.time())\n",
    "        om, os = divmod(time_now - time_start_overall[0], 60)\n",
    "        m, s = divmod(time_now - time_start[0], 60)\n",
    "        time_start[0] = time_now\n",
    "        return ' overall_time: ' + str(om) + 'm' + str(os) + 's' + ' time_from_previous_call: ' + str(m) + 'm' + str(s) + 's'\n",
    "    return time_taken\n",
    "time_taken = timer()\n",
    "\n",
    "sr = 16000\n",
    "\n",
    "unknowns = 'bed bird cat dog eight five four happy house marvin nine one seven sheila six three tree two wow zero'.split()\n",
    "knowns = 'yes no up down left right on off stop go'.split()\n",
    "silence = 'silence'.split()\n",
    "labels = knowns + silence + ['unknown'] \n",
    "num_classes = len(labels)\n",
    "\n",
    "LABEL_TO_FILE_NAMES = {}\n",
    "for label in knowns:\n",
    "    for filename in os.listdir('../train/audio/' + label):\n",
    "        if not filename.endswith('.wav'):\n",
    "            continue\n",
    "        LABEL_TO_FILE_NAMES.setdefault(label, [])\n",
    "        LABEL_TO_FILE_NAMES[label].append('../train/audio/' + label + '/' + filename)\n",
    "\n",
    "for label in unknowns:\n",
    "    for filename in os.listdir('../train/audio/' + label):\n",
    "        if not filename.endswith('.wav'):\n",
    "            continue\n",
    "        LABEL_TO_FILE_NAMES.setdefault('unknown', [])\n",
    "        LABEL_TO_FILE_NAMES['unknown'].append('../train/audio/' + label + '/' + filename)\n",
    "\n",
    "\n",
    "VALIDATION_LABEL_TO_FILE_NAMES = {}\n",
    "TRAIN_LABEL_TO_FILE_NAMES = {}\n",
    "for label, filenames in LABEL_TO_FILE_NAMES.items():\n",
    "    np.random.shuffle(filenames)\n",
    "    if label == 'unknown':\n",
    "        VALIDATION_LABEL_TO_FILE_NAMES[label] = filenames[0:4000]\n",
    "        TRAIN_LABEL_TO_FILE_NAMES[label] = filenames[4000:]\n",
    "    else:\n",
    "        VALIDATION_LABEL_TO_FILE_NAMES[label] = filenames[0:400]\n",
    "        TRAIN_LABEL_TO_FILE_NAMES[label] = filenames[400:]\n",
    "\n",
    "FILE_TO_SAMPLES = {}\n",
    "FILE_TO_LABEL = {}\n",
    "for label, filenames in LABEL_TO_FILE_NAMES.items():\n",
    "    for filename in filenames:\n",
    "        samples, _ = librosa.load(filename, sr=sr)\n",
    "        FILE_TO_SAMPLES[filename] = samples\n",
    "        FILE_TO_LABEL[filename] = label\n",
    "        if len(FILE_TO_LABEL) % 5000 == 0:\n",
    "            print(len(FILE_TO_LABEL), time_taken())\n",
    "    \n",
    "\n",
    "UNCOLORED_NOISES = []\n",
    "UNCOLORED_NOISES += librosa.load('../train/audio/_background_noise_/doing_the_dishes.wav', sr=sr)[0].tolist()\n",
    "UNCOLORED_NOISES += librosa.load('../train/audio/_background_noise_/dude_miaowing.wav', sr=sr)[0].tolist()\n",
    "UNCOLORED_NOISES += librosa.load('../train/audio/_background_noise_/exercise_bike.wav', sr=sr)[0].tolist()\n",
    "UNCOLORED_NOISES += librosa.load('../train/audio/_background_noise_/running_tap.wav', sr=sr)[0].tolist()\n",
    "\n",
    "\n",
    "def get_silence():\n",
    "    choice = np.random.choice([0, 1, 2], p=[0.01, 0.15, 0.84])\n",
    "    if choice == 0:\n",
    "        return np.zeros((16000))\n",
    "    if choice == 1:\n",
    "        idx = random.randint(0, len(UNCOLORED_NOISES) - sr)\n",
    "        return np.array(UNCOLORED_NOISES[idx:idx+sr], dtype=np.float32)\n",
    "    else:\n",
    "        return np.array(acoustics.generator.noise(16000, color=np.random.choice(['pink', 'white']))/3, np.float32)\n",
    "\n",
    "def pad_zeros(samples):\n",
    "    if len(samples) < sr:\n",
    "        diff = sr - len(samples)\n",
    "        diff_div = diff // 2\n",
    "        samples = np.lib.pad(samples, (diff_div, diff - diff_div), 'constant', constant_values = (0, 0))\n",
    "    return samples\n",
    "\n",
    "def pitch_shift(samples, sr=sr):\n",
    "    return librosa.effects.pitch_shift(samples, sr=sr, n_steps=random.randint(1, 5))\n",
    "\n",
    "def get_shuffled_XY(X, Y):\n",
    "    m = X.shape[0]\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "    return shuffled_X, shuffled_Y\n",
    "\n",
    "def time_shift(arr):\n",
    "    num = np.random.uniform(0, 0.2) * len(arr)\n",
    "    num = int(num)\n",
    "    result = np.empty_like(arr)\n",
    "    if num > 0:\n",
    "        result[:num] = 0\n",
    "        result[num:] = arr[:-num]\n",
    "    elif num < 0:\n",
    "        result[num:] = 0\n",
    "        result[:num] = arr[-num:]\n",
    "    else:\n",
    "        result = arr\n",
    "    return np.array(result)\n",
    "        \n",
    "def flip_transform(wave):\n",
    "    if np.random.choice([0, 1]):\n",
    "        return -wave\n",
    "\n",
    "def noise_mix(wave):\n",
    "    noise = get_silence()\n",
    "    noise_limit = random.uniform(0, 0.1)\n",
    "    wave = (1 - noise_limit) * wave + noise_limit * noise\n",
    "    return wave\n",
    "\n",
    "def get_melspectrogram(samples):\n",
    "    S = librosa.feature.melspectrogram(samples, sr=sr, n_mels=72, hop_length=223, n_fft=512)\n",
    "    spec = librosa.power_to_db(S, ref=np.max)\n",
    "    spec = np.repeat(spec[np.newaxis,:,:,np.newaxis], 3, axis=3)\n",
    "    return spec\n",
    "\n",
    "def get_transformed_samples(samples):\n",
    "    samples = pad_zeros(samples)\n",
    "    samples = time_shift(samples)\n",
    "    samples = noise_mix(samples)\n",
    "    if np.random.choice([0, 1]):\n",
    "        samples = -samples\n",
    "    stdx = np.std(samples)\n",
    "    if stdx:\n",
    "        sampels = samples / stdx\n",
    "    #samples = flip_transform(samples)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'silence', 'unknown']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing train label to filename lengths\n",
      "on 1967\n",
      "off 1957\n",
      "down 1959\n",
      "up 1975\n",
      "no 1975\n",
      "stop 1980\n",
      "left 1953\n",
      "right 1967\n",
      "go 1972\n",
      "yes 1977\n",
      "unknown 37039\n",
      "printing validation label to filename lengths\n",
      "on 400\n",
      "off 400\n",
      "down 400\n",
      "up 400\n",
      "no 400\n",
      "stop 400\n",
      "left 400\n",
      "right 400\n",
      "go 400\n",
      "yes 400\n",
      "unknown 4000\n"
     ]
    }
   ],
   "source": [
    "print('printing train label to filename lengths')\n",
    "for label, filenames in TRAIN_LABEL_TO_FILE_NAMES.items():\n",
    "    print(label, len(filenames))\n",
    "print('printing validation label to filename lengths')\n",
    "for label, filenames in VALIDATION_LABEL_TO_FILE_NAMES.items():\n",
    "    print(label, len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " overall_time: 0m43s time_from_previous_call: 0m20s\n"
     ]
    }
   ],
   "source": [
    "print(time_taken())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_data_generator():\n",
    "    XV = np.zeros((256, 72, 72, 3))\n",
    "    YV = np.zeros((256, num_classes))\n",
    "    while True:\n",
    "        for idx in range(256):\n",
    "            random_label = np.random.choice(labels)\n",
    "            if random_label == 'silence':\n",
    "                samples = get_silence()\n",
    "            else:\n",
    "                random_filename = np.random.choice(VALIDATION_LABEL_TO_FILE_NAMES[random_label])\n",
    "                samples = FILE_TO_SAMPLES[random_filename]\n",
    "                samples = get_transformed_samples(samples)\n",
    "            spec = get_melspectrogram(samples)\n",
    "            XV[idx, :, :] = spec\n",
    "            this_Y = [labels.index(random_label)]\n",
    "            this_Y = keras.utils.to_categorical(np.array(this_Y).astype(np.float32), num_classes)\n",
    "            YV[idx, :] = this_Y\n",
    "        yield XV, YV\n",
    "\n",
    "def train_data_generator():\n",
    "    XT = np.zeros((256, 72, 72, 3))\n",
    "    YT = np.zeros((256, num_classes))\n",
    "    while True:\n",
    "        for idx in range(256):\n",
    "            random_label = np.random.choice(labels)\n",
    "            if random_label == 'silence':\n",
    "                samples = get_silence()\n",
    "            else:\n",
    "                random_filename = np.random.choice(TRAIN_LABEL_TO_FILE_NAMES[random_label])\n",
    "                samples = FILE_TO_SAMPLES[random_filename]\n",
    "                samples = get_transformed_samples(samples)\n",
    "            spec = get_melspectrogram(samples)\n",
    "            XT[idx, :, :] = spec\n",
    "            this_Y = [labels.index(random_label)]\n",
    "            this_Y = keras.utils.to_categorical(np.array(this_Y).astype(np.float32), num_classes)\n",
    "            YT[idx, :] = this_Y\n",
    "        yield XT, YT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1251 - acc: 0.9695Epoch 00001: val_acc improved from -inf to 0.96367, saving model to model-xception-resumed2-01-0.96-0.14.h5\n",
      "200/200 [==============================] - 455s 2s/step - loss: 0.1251 - acc: 0.9695 - val_loss: 0.1430 - val_acc: 0.9637\n",
      "Epoch 2/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1233 - acc: 0.9689Epoch 00002: val_acc improved from 0.96367 to 0.96816, saving model to model-xception-resumed2-02-0.97-0.12.h5\n",
      "200/200 [==============================] - 405s 2s/step - loss: 0.1235 - acc: 0.9688 - val_loss: 0.1232 - val_acc: 0.9682\n",
      "Epoch 3/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1172 - acc: 0.9716Epoch 00003: val_acc did not improve\n",
      "200/200 [==============================] - 410s 2s/step - loss: 0.1175 - acc: 0.9715 - val_loss: 0.1358 - val_acc: 0.9676\n",
      "Epoch 4/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1262 - acc: 0.9689Epoch 00004: val_acc did not improve\n",
      "200/200 [==============================] - 410s 2s/step - loss: 0.1264 - acc: 0.9689 - val_loss: 0.1384 - val_acc: 0.9650\n",
      "Epoch 5/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1287 - acc: 0.9689Epoch 00005: val_acc did not improve\n",
      "200/200 [==============================] - 408s 2s/step - loss: 0.1288 - acc: 0.9688 - val_loss: 0.1472 - val_acc: 0.9668\n",
      "Epoch 6/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1180 - acc: 0.9708Epoch 00006: val_acc did not improve\n",
      "200/200 [==============================] - 403s 2s/step - loss: 0.1177 - acc: 0.9709 - val_loss: 0.1342 - val_acc: 0.9646\n",
      "Epoch 7/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1227 - acc: 0.9701Epoch 00007: val_acc did not improve\n",
      "\n",
      "Epoch 00007: reducing learning rate to 1.6000001778593287e-06.\n",
      "200/200 [==============================] - 411s 2s/step - loss: 0.1226 - acc: 0.9701 - val_loss: 0.1332 - val_acc: 0.9670\n",
      "Epoch 8/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1166 - acc: 0.9712Epoch 00008: val_acc did not improve\n",
      "200/200 [==============================] - 409s 2s/step - loss: 0.1166 - acc: 0.9712 - val_loss: 0.1534 - val_acc: 0.9621\n",
      "Epoch 9/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1219 - acc: 0.9697Epoch 00009: val_acc did not improve\n",
      "200/200 [==============================] - 406s 2s/step - loss: 0.1219 - acc: 0.9697 - val_loss: 0.1524 - val_acc: 0.9623\n",
      "Epoch 10/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1193 - acc: 0.9720Epoch 00010: val_acc did not improve\n",
      "200/200 [==============================] - 409s 2s/step - loss: 0.1188 - acc: 0.9721 - val_loss: 0.1446 - val_acc: 0.9650\n",
      "Epoch 11/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1164 - acc: 0.9709Epoch 00011: val_acc did not improve\n",
      "\n",
      "Epoch 00011: reducing learning rate to 3.200000264769187e-07.\n",
      "200/200 [==============================] - 399s 2s/step - loss: 0.1164 - acc: 0.9709 - val_loss: 0.1345 - val_acc: 0.9668\n",
      "Epoch 12/200\n",
      " 98/200 [=============>................] - ETA: 2:19 - loss: 0.1178 - acc: 0.9704"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "# model = keras.applications.xception.Xception(include_top=True, weights=None, input_tensor=None, input_shape=None, pooling=None, classes=num_classes)\n",
    "# model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#               optimizer=keras.optimizers.Adam(),\n",
    "#               metrics=['accuracy'])\n",
    "model = load_model('model-xception-resumed-07-0.97-0.13.h5')\n",
    "checkpoint = ModelCheckpoint('model-xception-resumed2-{epoch:02d}-{val_acc:.2f}-{val_loss:.2f}.h5',\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             mode='max')\n",
    "earlystopping = EarlyStopping(monitor='val_acc', patience=5)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=1e-8, verbose=1)\n",
    "callback_list = [checkpoint, reduce_lr]\n",
    "\n",
    "train_generator = train_data_generator()\n",
    "validation_generator = validation_data_generator()\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=200, \n",
    "                    epochs=epochs, \n",
    "                    callbacks=callback_list,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=20,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time_taken())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
