{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np # linear algebra\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, Convolution2D, Activation\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import os\n",
    "import random\n",
    "from scipy.io import wavfile\n",
    "from subprocess import check_output\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import acoustics\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import random\n",
    "\n",
    "def timer():\n",
    "    time_start = [int(time.time())]\n",
    "    time_start_overall = [int(time.time())]\n",
    "\n",
    "    def time_taken():\n",
    "        time_now = int(time.time())\n",
    "        om, os = divmod(time_now - time_start_overall[0], 60)\n",
    "        m, s = divmod(time_now - time_start[0], 60)\n",
    "        time_start[0] = time_now\n",
    "        return ' overall_time: ' + str(om) + 'm' + str(os) + 's' + ' time_from_previous_call: ' + str(m) + 'm' + str(s) + 's'\n",
    "    return time_taken\n",
    "time_taken = timer()\n",
    "\n",
    "sr = 16000\n",
    "\n",
    "unknowns = 'bed bird cat dog eight five four happy house marvin nine one seven sheila six three tree two wow zero'.split()\n",
    "knowns = 'yes no up down left right on off stop go'.split()\n",
    "silence = 'silence'.split()\n",
    "labels = knowns + silence + ['unknown'] \n",
    "num_classes = len(labels)\n",
    "\n",
    "LABEL_TO_FILE_NAMES = {}\n",
    "VALIDATION_LABEL_TO_FILE_NAMES = {}\n",
    "TRAIN_LABEL_TO_FILE_NAMES = {}\n",
    "FILE_TO_LABEL = {}\n",
    "with open('train.csv') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        line = line.split(',')\n",
    "        LABEL_TO_FILE_NAMES.setdefault(line[1], [])\n",
    "        LABEL_TO_FILE_NAMES[line[1]].append(line[0])\n",
    "        TRAIN_LABEL_TO_FILE_NAMES.setdefault(line[1], [])\n",
    "        TRAIN_LABEL_TO_FILE_NAMES[line[1]].append(line[0])\n",
    "        FILE_TO_LABEL[line[0]] = line[1]\n",
    "with open('validation.csv') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        line = line.split(',')\n",
    "        LABEL_TO_FILE_NAMES.setdefault(line[1], [])\n",
    "        LABEL_TO_FILE_NAMES[line[1]].append(line[0])\n",
    "        VALIDATION_LABEL_TO_FILE_NAMES.setdefault(line[1], [])\n",
    "        VALIDATION_LABEL_TO_FILE_NAMES[line[1]].append(line[0])\n",
    "        FILE_TO_LABEL[line[0]] = line[1]\n",
    "\n",
    "\n",
    "def file_to_sample(filename):\n",
    "    samples, _ = librosa.load(filename, sr=sr)\n",
    "    return samples\n",
    "    \n",
    "\n",
    "UNCOLORED_NOISES = []\n",
    "UNCOLORED_NOISES += librosa.load('../train/audio/_background_noise_/doing_the_dishes.wav', sr=sr)[0].tolist()\n",
    "UNCOLORED_NOISES += librosa.load('../train/audio/_background_noise_/dude_miaowing.wav', sr=sr)[0].tolist()\n",
    "UNCOLORED_NOISES += librosa.load('../train/audio/_background_noise_/exercise_bike.wav', sr=sr)[0].tolist()\n",
    "UNCOLORED_NOISES += librosa.load('../train/audio/_background_noise_/running_tap.wav', sr=sr)[0].tolist()\n",
    "\n",
    "\n",
    "def get_silence():\n",
    "    choice = np.random.choice([0, 1, 2, 4], p=[0.01, 0.10, 0.70, 0.19])\n",
    "    if choice == 0:\n",
    "        return np.zeros((16000))\n",
    "    elif choice == 1:\n",
    "        idx = random.randint(0, len(UNCOLORED_NOISES) - sr)\n",
    "        return np.array(UNCOLORED_NOISES[idx:idx+sr], dtype=np.float32)\n",
    "    elif choice == 3:\n",
    "        return np.array(acoustics.generator.noise(16000, color=np.random.choice(['pink', 'white']))/3, np.float32)\n",
    "    else:\n",
    "        random_silence_file = np.random.choice(LABEL_TO_FILE_NAMES['silence'])\n",
    "        return file_to_sample(random_silence_file)\n",
    "\n",
    "def pad_zeros(samples):\n",
    "    if len(samples) < sr:\n",
    "        diff = sr - len(samples)\n",
    "        diff_div = diff // 2\n",
    "        samples = np.lib.pad(samples, (diff_div, diff - diff_div), 'constant', constant_values = (0, 0))\n",
    "    return samples\n",
    "\n",
    "def pitch_shift(samples, sr=sr):\n",
    "    return librosa.effects.pitch_shift(samples, sr=sr, n_steps=random.randint(1, 5))\n",
    "\n",
    "def get_shuffled_XY(X, Y):\n",
    "    m = X.shape[0]\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "    return shuffled_X, shuffled_Y\n",
    "\n",
    "def time_shift(arr):\n",
    "    num = np.random.uniform(0, 0.2) * len(arr)\n",
    "    num = int(num)\n",
    "    result = np.empty_like(arr)\n",
    "    if num > 0:\n",
    "        result[:num] = 0\n",
    "        result[num:] = arr[:-num]\n",
    "    elif num < 0:\n",
    "        result[num:] = 0\n",
    "        result[:num] = arr[-num:]\n",
    "    else:\n",
    "        result = arr\n",
    "    return np.array(result)\n",
    "        \n",
    "def flip_transform(wave):\n",
    "    if np.random.choice([0, 1]):\n",
    "        return -wave\n",
    "\n",
    "def noise_mix(wave):\n",
    "    noise = get_silence()\n",
    "    noise_limit = random.uniform(0, 0.1)\n",
    "    wave = (1 - noise_limit) * wave + noise_limit * noise\n",
    "    return wave\n",
    "\n",
    "# 72 * 72\n",
    "def get_melspectrogram(samples):\n",
    "    S = librosa.feature.melspectrogram(samples, sr=sr, n_mels=72, hop_length=223, n_fft=512)\n",
    "    spec = librosa.power_to_db(S, ref=np.max)\n",
    "    spec = np.repeat(spec[np.newaxis,:,:,np.newaxis], 3, axis=3)\n",
    "    return spec\n",
    "\n",
    "# 150 * 150\n",
    "def get_mel_of_150_150(samples):\n",
    "    S = librosa.feature.melspectrogram(samples, sr=sr, n_mels=150, hop_length=107, n_fft=512)\n",
    "    spec = librosa.power_to_db(S, ref=np.max)\n",
    "    spec = np.repeat(spec[np.newaxis,:,:,np.newaxis], 3, axis=3)\n",
    "    return spec\n",
    "\n",
    "# 197 * 161\n",
    "def log_specgram(audio, sample_rate=16000, window_size=20,\n",
    "                 step_size=15, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    spec = np.log(spec.T.astype(np.float32) + eps)\n",
    "    return np.repeat(spec[np.newaxis,:,:,np.newaxis], 3, axis=3)\n",
    "\n",
    "def get_transformed_samples(samples):\n",
    "    samples = pad_zeros(samples)\n",
    "    samples = time_shift(samples)\n",
    "    samples = noise_mix(samples)\n",
    "    if np.random.choice([0, 1]):\n",
    "        samples = -samples\n",
    "    stdx = np.std(samples)\n",
    "    if stdx:\n",
    "        sampels = samples / stdx\n",
    "    #samples = flip_transform(samples)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'silence', 'unknown']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing train label to filename lengths\n",
      "unknown 88628\n",
      "stop 7044\n",
      "on 7637\n",
      "no 7539\n",
      "down 6203\n",
      "left 6668\n",
      "go 5464\n",
      "off 6810\n",
      "yes 6562\n",
      "right 7284\n",
      "up 6300\n",
      "silence 10208\n",
      "printing validation label to filename lengths\n",
      "unknown 9847\n",
      "stop 782\n",
      "on 848\n",
      "no 837\n",
      "down 689\n",
      "left 740\n",
      "go 607\n",
      "off 756\n",
      "yes 729\n",
      "right 809\n",
      "up 700\n",
      "silence 1134\n"
     ]
    }
   ],
   "source": [
    "print('printing train label to filename lengths')\n",
    "for label, filenames in TRAIN_LABEL_TO_FILE_NAMES.items():\n",
    "    print(label, len(filenames))\n",
    "print('printing validation label to filename lengths')\n",
    "for label, filenames in VALIDATION_LABEL_TO_FILE_NAMES.items():\n",
    "    print(label, len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " overall_time: 0m9s time_from_previous_call: 0m9s\n"
     ]
    }
   ],
   "source": [
    "print(time_taken())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "def validation_data_generator():\n",
    "    XV = np.zeros((batch_size, 150, 150, 3))\n",
    "    YV = np.zeros((batch_size, num_classes))\n",
    "    while True:\n",
    "        for idx in range(batch_size):\n",
    "            random_label = np.random.choice(labels)\n",
    "            if random_label == 'silence':\n",
    "                samples = get_silence()\n",
    "            else:\n",
    "                random_filename = np.random.choice(VALIDATION_LABEL_TO_FILE_NAMES[random_label])\n",
    "                samples = file_to_sample(random_filename)\n",
    "                samples = get_transformed_samples(samples)\n",
    "            spec = get_mel_of_150_150(samples)\n",
    "            XV[idx, :, :] = spec\n",
    "            this_Y = [labels.index(random_label)]\n",
    "            this_Y = keras.utils.to_categorical(np.array(this_Y).astype(np.float32), num_classes)\n",
    "            YV[idx, :] = this_Y\n",
    "        yield XV, YV\n",
    "\n",
    "def train_data_generator():\n",
    "    XT = np.zeros((batch_size, 150, 150, 3))\n",
    "    YT = np.zeros((batch_size, num_classes))\n",
    "    while True:\n",
    "        for idx in range(batch_size):\n",
    "            random_label = np.random.choice(labels)\n",
    "            if random_label == 'silence':\n",
    "                samples = get_silence()\n",
    "            else:\n",
    "                random_filename = np.random.choice(TRAIN_LABEL_TO_FILE_NAMES[random_label])\n",
    "                samples = file_to_sample(random_filename)\n",
    "                samples = get_transformed_samples(samples)\n",
    "            spec = get_mel_of_150_150(samples)\n",
    "            XT[idx, :, :] = spec\n",
    "            this_Y = [labels.index(random_label)]\n",
    "            this_Y = keras.utils.to_categorical(np.array(this_Y).astype(np.float32), num_classes)\n",
    "            YT[idx, :] = this_Y\n",
    "        yield XT, YT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.6340 - acc: 0.8021Epoch 00001: val_acc improved from -inf to 0.75625, saving model to model-melspec-inception-resnet-v2-0-01-0.76-0.88.h5\n",
      "200/200 [==============================] - 537s 3s/step - loss: 0.6323 - acc: 0.8026 - val_loss: 0.8801 - val_acc: 0.7562\n",
      "Epoch 2/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.3646 - acc: 0.9046Epoch 00002: val_acc improved from 0.75625 to 0.82539, saving model to model-melspec-inception-resnet-v2-0-02-0.83-0.66.h5\n",
      "200/200 [==============================] - 351s 2s/step - loss: 0.3644 - acc: 0.9045 - val_loss: 0.6650 - val_acc: 0.8254\n",
      "Epoch 3/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.3080 - acc: 0.9203Epoch 00003: val_acc improved from 0.82539 to 0.90391, saving model to model-melspec-inception-resnet-v2-0-03-0.90-0.35.h5\n",
      "200/200 [==============================] - 352s 2s/step - loss: 0.3083 - acc: 0.9204 - val_loss: 0.3479 - val_acc: 0.9039\n",
      "Epoch 4/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.2804 - acc: 0.9260Epoch 00004: val_acc did not improve\n",
      "200/200 [==============================] - 347s 2s/step - loss: 0.2804 - acc: 0.9259 - val_loss: 0.3774 - val_acc: 0.8957\n",
      "Epoch 5/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.2732 - acc: 0.9334Epoch 00005: val_acc improved from 0.90391 to 0.92305, saving model to model-melspec-inception-resnet-v2-0-05-0.92-0.32.h5\n",
      "200/200 [==============================] - 352s 2s/step - loss: 0.2736 - acc: 0.9333 - val_loss: 0.3180 - val_acc: 0.9230\n",
      "Epoch 6/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.2687 - acc: 0.9337Epoch 00006: val_acc did not improve\n",
      "200/200 [==============================] - 348s 2s/step - loss: 0.2688 - acc: 0.9336 - val_loss: 0.3646 - val_acc: 0.9086\n",
      "Epoch 7/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.2659 - acc: 0.9378Epoch 00007: val_acc did not improve\n",
      "200/200 [==============================] - 349s 2s/step - loss: 0.2663 - acc: 0.9377 - val_loss: 0.5384 - val_acc: 0.8617\n",
      "Epoch 8/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.2356 - acc: 0.9428Epoch 00008: val_acc did not improve\n",
      "200/200 [==============================] - 346s 2s/step - loss: 0.2358 - acc: 0.9427 - val_loss: 0.2886 - val_acc: 0.9176\n",
      "Epoch 9/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.2152 - acc: 0.9464Epoch 00009: val_acc did not improve\n",
      "200/200 [==============================] - 343s 2s/step - loss: 0.2150 - acc: 0.9464 - val_loss: 0.3059 - val_acc: 0.9133\n",
      "Epoch 10/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.2153 - acc: 0.9457Epoch 00010: val_acc did not improve\n",
      "200/200 [==============================] - 346s 2s/step - loss: 0.2151 - acc: 0.9457 - val_loss: 0.2882 - val_acc: 0.9223\n",
      "Epoch 11/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.2089 - acc: 0.9499Epoch 00011: val_acc did not improve\n",
      "200/200 [==============================] - 348s 2s/step - loss: 0.2086 - acc: 0.9500 - val_loss: 0.2870 - val_acc: 0.9164\n",
      "Epoch 12/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1953 - acc: 0.9517Epoch 00012: val_acc did not improve\n",
      "200/200 [==============================] - 348s 2s/step - loss: 0.1953 - acc: 0.9517 - val_loss: 0.3005 - val_acc: 0.9164\n",
      "Epoch 13/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.2008 - acc: 0.9516Epoch 00013: val_acc improved from 0.92305 to 0.93594, saving model to model-melspec-inception-resnet-v2-0-13-0.94-0.23.h5\n",
      "200/200 [==============================] - 345s 2s/step - loss: 0.2010 - acc: 0.9517 - val_loss: 0.2316 - val_acc: 0.9359\n",
      "Epoch 14/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.2182 - acc: 0.9515Epoch 00014: val_acc improved from 0.93594 to 0.94531, saving model to model-melspec-inception-resnet-v2-0-14-0.95-0.23.h5\n",
      "200/200 [==============================] - 343s 2s/step - loss: 0.2179 - acc: 0.9515 - val_loss: 0.2340 - val_acc: 0.9453\n",
      "Epoch 15/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1916 - acc: 0.9542Epoch 00015: val_acc improved from 0.94531 to 0.95469, saving model to model-melspec-inception-resnet-v2-0-15-0.95-0.18.h5\n",
      "200/200 [==============================] - 347s 2s/step - loss: 0.1913 - acc: 0.9543 - val_loss: 0.1826 - val_acc: 0.9547\n",
      "Epoch 16/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1818 - acc: 0.9558Epoch 00016: val_acc did not improve\n",
      "200/200 [==============================] - 342s 2s/step - loss: 0.1823 - acc: 0.9557 - val_loss: 0.2292 - val_acc: 0.9391\n",
      "Epoch 17/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1885 - acc: 0.9550Epoch 00017: val_acc did not improve\n",
      "200/200 [==============================] - 343s 2s/step - loss: 0.1879 - acc: 0.9551 - val_loss: 0.3103 - val_acc: 0.9191\n",
      "Epoch 18/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1815 - acc: 0.9572Epoch 00018: val_acc did not improve\n",
      "200/200 [==============================] - 344s 2s/step - loss: 0.1814 - acc: 0.9572 - val_loss: 0.2228 - val_acc: 0.9395\n",
      "Epoch 19/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1791 - acc: 0.9589Epoch 00019: val_acc did not improve\n",
      "200/200 [==============================] - 346s 2s/step - loss: 0.1786 - acc: 0.9590 - val_loss: 0.3053 - val_acc: 0.9242\n",
      "Epoch 20/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1835 - acc: 0.9586Epoch 00020: val_acc did not improve\n",
      "\n",
      "Epoch 00020: reducing learning rate to 0.00020000000949949026.\n",
      "200/200 [==============================] - 346s 2s/step - loss: 0.1836 - acc: 0.9586 - val_loss: 0.2441 - val_acc: 0.9367\n",
      "Epoch 21/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1469 - acc: 0.9677Epoch 00021: val_acc improved from 0.95469 to 0.95820, saving model to model-melspec-inception-resnet-v2-0-21-0.96-0.16.h5\n",
      "200/200 [==============================] - 346s 2s/step - loss: 0.1466 - acc: 0.9677 - val_loss: 0.1592 - val_acc: 0.9582\n",
      "Epoch 22/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1370 - acc: 0.9708Epoch 00022: val_acc improved from 0.95820 to 0.96914, saving model to model-melspec-inception-resnet-v2-0-22-0.97-0.14.h5\n",
      "200/200 [==============================] - 343s 2s/step - loss: 0.1367 - acc: 0.9708 - val_loss: 0.1419 - val_acc: 0.9691\n",
      "Epoch 23/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1287 - acc: 0.9730Epoch 00023: val_acc did not improve\n",
      "200/200 [==============================] - 341s 2s/step - loss: 0.1292 - acc: 0.9730 - val_loss: 0.1476 - val_acc: 0.9664\n",
      "Epoch 24/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1375 - acc: 0.9727Epoch 00024: val_acc did not improve\n",
      "200/200 [==============================] - 344s 2s/step - loss: 0.1378 - acc: 0.9726 - val_loss: 0.1657 - val_acc: 0.9605\n",
      "Epoch 25/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1197 - acc: 0.9750Epoch 00025: val_acc improved from 0.96914 to 0.96953, saving model to model-melspec-inception-resnet-v2-0-25-0.97-0.13.h5\n",
      "200/200 [==============================] - 347s 2s/step - loss: 0.1198 - acc: 0.9750 - val_loss: 0.1330 - val_acc: 0.9695\n",
      "Epoch 26/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1220 - acc: 0.9758Epoch 00026: val_acc did not improve\n",
      "200/200 [==============================] - 345s 2s/step - loss: 0.1221 - acc: 0.9757 - val_loss: 0.1408 - val_acc: 0.9641\n",
      "Epoch 27/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1214 - acc: 0.9748Epoch 00027: val_acc did not improve\n",
      "200/200 [==============================] - 341s 2s/step - loss: 0.1214 - acc: 0.9748 - val_loss: 0.1763 - val_acc: 0.9617\n",
      "Epoch 28/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1229 - acc: 0.9748Epoch 00028: val_acc did not improve\n",
      "200/200 [==============================] - 345s 2s/step - loss: 0.1229 - acc: 0.9749 - val_loss: 0.1424 - val_acc: 0.9664\n",
      "Epoch 29/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1182 - acc: 0.9763Epoch 00029: val_acc did not improve\n",
      "200/200 [==============================] - 345s 2s/step - loss: 0.1183 - acc: 0.9762 - val_loss: 0.1483 - val_acc: 0.9664\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 1s - loss: 0.1222 - acc: 0.9747Epoch 00030: val_acc did not improve\n",
      "200/200 [==============================] - 345s 2s/step - loss: 0.1225 - acc: 0.9745 - val_loss: 0.1303 - val_acc: 0.9641\n",
      "Epoch 31/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1177 - acc: 0.9761Epoch 00031: val_acc did not improve\n",
      "200/200 [==============================] - 345s 2s/step - loss: 0.1177 - acc: 0.9762 - val_loss: 0.1479 - val_acc: 0.9645\n",
      "Epoch 32/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1195 - acc: 0.9760Epoch 00032: val_acc did not improve\n",
      "200/200 [==============================] - 343s 2s/step - loss: 0.1191 - acc: 0.9761 - val_loss: 0.1534 - val_acc: 0.9645\n",
      "Epoch 33/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1192 - acc: 0.9762Epoch 00033: val_acc did not improve\n",
      "200/200 [==============================] - 347s 2s/step - loss: 0.1196 - acc: 0.9762 - val_loss: 0.1658 - val_acc: 0.9609\n",
      "Epoch 34/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1228 - acc: 0.9758Epoch 00034: val_acc did not improve\n",
      "200/200 [==============================] - 345s 2s/step - loss: 0.1231 - acc: 0.9757 - val_loss: 0.1446 - val_acc: 0.9688\n",
      "Epoch 35/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1083 - acc: 0.9805Epoch 00035: val_acc improved from 0.96953 to 0.96992, saving model to model-melspec-inception-resnet-v2-0-35-0.97-0.12.h5\n",
      "200/200 [==============================] - 344s 2s/step - loss: 0.1088 - acc: 0.9804 - val_loss: 0.1189 - val_acc: 0.9699\n",
      "Epoch 36/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1140 - acc: 0.9786Epoch 00036: val_acc improved from 0.96992 to 0.97266, saving model to model-melspec-inception-resnet-v2-0-36-0.97-0.12.h5\n",
      "200/200 [==============================] - 345s 2s/step - loss: 0.1138 - acc: 0.9787 - val_loss: 0.1198 - val_acc: 0.9727\n",
      "Epoch 37/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1107 - acc: 0.9798Epoch 00037: val_acc did not improve\n",
      "200/200 [==============================] - 345s 2s/step - loss: 0.1107 - acc: 0.9798 - val_loss: 0.1360 - val_acc: 0.9688\n",
      "Epoch 38/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1112 - acc: 0.9782Epoch 00038: val_acc did not improve\n",
      "200/200 [==============================] - 345s 2s/step - loss: 0.1114 - acc: 0.9781 - val_loss: 0.1401 - val_acc: 0.9719\n",
      "Epoch 39/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1154 - acc: 0.9781Epoch 00039: val_acc did not improve\n",
      "200/200 [==============================] - 343s 2s/step - loss: 0.1156 - acc: 0.9780 - val_loss: 0.1526 - val_acc: 0.9652\n",
      "Epoch 40/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1091 - acc: 0.9800Epoch 00040: val_acc did not improve\n",
      "\n",
      "Epoch 00040: reducing learning rate to 4.0000001899898055e-05.\n",
      "200/200 [==============================] - 343s 2s/step - loss: 0.1096 - acc: 0.9800 - val_loss: 0.1514 - val_acc: 0.9648\n",
      "Epoch 41/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1062 - acc: 0.9804Epoch 00041: val_acc did not improve\n",
      "200/200 [==============================] - 344s 2s/step - loss: 0.1061 - acc: 0.9804 - val_loss: 0.1469 - val_acc: 0.9668\n",
      "Epoch 42/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0996 - acc: 0.9825Epoch 00042: val_acc did not improve\n",
      "200/200 [==============================] - 346s 2s/step - loss: 0.0999 - acc: 0.9824 - val_loss: 0.1570 - val_acc: 0.9645\n",
      "Epoch 43/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1009 - acc: 0.9818Epoch 00043: val_acc did not improve\n",
      "200/200 [==============================] - 343s 2s/step - loss: 0.1011 - acc: 0.9818 - val_loss: 0.1484 - val_acc: 0.9645\n",
      "Epoch 44/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0912 - acc: 0.9837Epoch 00044: val_acc did not improve\n",
      "\n",
      "Epoch 00044: reducing learning rate to 8.000000525498762e-06.\n",
      "200/200 [==============================] - 344s 2s/step - loss: 0.0911 - acc: 0.9838 - val_loss: 0.1504 - val_acc: 0.9684\n",
      "Epoch 45/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0951 - acc: 0.9838Epoch 00045: val_acc did not improve\n",
      "200/200 [==============================] - 343s 2s/step - loss: 0.0953 - acc: 0.9838 - val_loss: 0.1368 - val_acc: 0.9715\n",
      "Epoch 46/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0921 - acc: 0.9835Epoch 00046: val_acc did not improve\n",
      "200/200 [==============================] - 343s 2s/step - loss: 0.0925 - acc: 0.9834 - val_loss: 0.1398 - val_acc: 0.9699\n",
      "Epoch 47/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0953 - acc: 0.9825Epoch 00047: val_acc improved from 0.97266 to 0.97539, saving model to model-melspec-inception-resnet-v2-0-47-0.98-0.11.h5\n",
      "200/200 [==============================] - 347s 2s/step - loss: 0.0953 - acc: 0.9825 - val_loss: 0.1112 - val_acc: 0.9754\n",
      "Epoch 48/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0973 - acc: 0.9832Epoch 00048: val_acc did not improve\n",
      "200/200 [==============================] - 342s 2s/step - loss: 0.0975 - acc: 0.9832 - val_loss: 0.1469 - val_acc: 0.9668\n",
      "Epoch 49/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0909 - acc: 0.9840Epoch 00049: val_acc did not improve\n",
      "200/200 [==============================] - 343s 2s/step - loss: 0.0907 - acc: 0.9840 - val_loss: 0.1329 - val_acc: 0.9715\n",
      "Epoch 50/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1001 - acc: 0.9824Epoch 00050: val_acc did not improve\n",
      "200/200 [==============================] - 343s 2s/step - loss: 0.1000 - acc: 0.9824 - val_loss: 0.1073 - val_acc: 0.9750\n",
      "Epoch 51/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0913 - acc: 0.9840Epoch 00051: val_acc did not improve\n",
      "200/200 [==============================] - 343s 2s/step - loss: 0.0914 - acc: 0.9840 - val_loss: 0.1346 - val_acc: 0.9664\n",
      "Epoch 52/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0907 - acc: 0.9839Epoch 00052: val_acc did not improve\n",
      "200/200 [==============================] - 343s 2s/step - loss: 0.0908 - acc: 0.9839 - val_loss: 0.1427 - val_acc: 0.9641\n",
      "Epoch 53/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0930 - acc: 0.9835Epoch 00053: val_acc did not improve\n",
      "200/200 [==============================] - 341s 2s/step - loss: 0.0926 - acc: 0.9836 - val_loss: 0.1185 - val_acc: 0.9750\n",
      "Epoch 54/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0868 - acc: 0.9852Epoch 00054: val_acc did not improve\n",
      "200/200 [==============================] - 343s 2s/step - loss: 0.0869 - acc: 0.9851 - val_loss: 0.1437 - val_acc: 0.9664\n",
      "Epoch 55/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0871 - acc: 0.9846Epoch 00055: val_acc did not improve\n",
      "\n",
      "Epoch 00055: reducing learning rate to 1.6000001778593287e-06.\n",
      "200/200 [==============================] - 342s 2s/step - loss: 0.0870 - acc: 0.9846 - val_loss: 0.1256 - val_acc: 0.9707\n",
      "Epoch 56/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0919 - acc: 0.9832Epoch 00056: val_acc did not improve\n",
      "200/200 [==============================] - 341s 2s/step - loss: 0.0921 - acc: 0.9832 - val_loss: 0.1468 - val_acc: 0.9633\n",
      "Epoch 57/200\n",
      "156/200 [======================>.......] - ETA: 1:04 - loss: 0.0922 - acc: 0.9837"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-27456043d44d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                     verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2145\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2146\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1837\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "model = keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=True, weights=None, input_tensor=None, input_shape=None, pooling=None, classes=num_classes)\n",
    "#model = keras.applications.xception.Xception(include_top=True, weights=None, input_tensor=None, input_shape=None, pooling=None, classes=num_classes)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "#model = load_model('model-xception-0-19-0.98-0.08.h5')\n",
    "checkpoint = ModelCheckpoint('model-melspec-inception-resnet-v2-0-{epoch:02d}-{val_acc:.2f}-{val_loss:.2f}.h5',\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             mode='max')\n",
    "earlystopping = EarlyStopping(monitor='val_acc', patience=5)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=1e-8, verbose=1)\n",
    "callback_list = [checkpoint, reduce_lr]\n",
    "\n",
    "train_generator = train_data_generator()\n",
    "validation_generator = validation_data_generator()\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=200, \n",
    "                    epochs=epochs, \n",
    "                    callbacks=callback_list,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=20,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time_taken())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
