{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np # linear algebra\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, Convolution2D, Activation\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import os\n",
    "import random\n",
    "from scipy.io import wavfile\n",
    "from subprocess import check_output\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import acoustics\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import random\n",
    "\n",
    "def timer():\n",
    "    time_start = [int(time.time())]\n",
    "    time_start_overall = [int(time.time())]\n",
    "\n",
    "    def time_taken():\n",
    "        time_now = int(time.time())\n",
    "        om, os = divmod(time_now - time_start_overall[0], 60)\n",
    "        m, s = divmod(time_now - time_start[0], 60)\n",
    "        time_start[0] = time_now\n",
    "        return ' overall_time: ' + str(om) + 'm' + str(os) + 's' + ' time_from_previous_call: ' + str(m) + 'm' + str(s) + 's'\n",
    "    return time_taken\n",
    "time_taken = timer()\n",
    "\n",
    "sr = 16000\n",
    "\n",
    "unknowns = 'bed bird cat dog eight five four happy house marvin nine one seven sheila six three tree two wow zero'.split()\n",
    "knowns = 'yes no up down left right on off stop go'.split()\n",
    "silence = 'silence'.split()\n",
    "labels = knowns + silence + ['unknown'] \n",
    "num_classes = len(labels)\n",
    "\n",
    "LABEL_TO_FILE_NAMES = {}\n",
    "VALIDATION_LABEL_TO_FILE_NAMES = {}\n",
    "TRAIN_LABEL_TO_FILE_NAMES = {}\n",
    "FILE_TO_LABEL = {}\n",
    "with open('train-88.csv') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        line = line.split(',')\n",
    "        LABEL_TO_FILE_NAMES.setdefault(line[1], [])\n",
    "        LABEL_TO_FILE_NAMES[line[1]].append(line[0])\n",
    "        TRAIN_LABEL_TO_FILE_NAMES.setdefault(line[1], [])\n",
    "        TRAIN_LABEL_TO_FILE_NAMES[line[1]].append(line[0])\n",
    "        FILE_TO_LABEL[line[0]] = line[1]\n",
    "with open('validation-88.csv') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        line = line.split(',')\n",
    "        LABEL_TO_FILE_NAMES.setdefault(line[1], [])\n",
    "        LABEL_TO_FILE_NAMES[line[1]].append(line[0])\n",
    "        VALIDATION_LABEL_TO_FILE_NAMES.setdefault(line[1], [])\n",
    "        VALIDATION_LABEL_TO_FILE_NAMES[line[1]].append(line[0])\n",
    "        FILE_TO_LABEL[line[0]] = line[1]\n",
    "\n",
    "\n",
    "def file_to_sample(filename):\n",
    "    samples, _ = librosa.load(filename, sr=sr)\n",
    "    return samples\n",
    "    \n",
    "\n",
    "UNCOLORED_NOISES = []\n",
    "UNCOLORED_NOISES += librosa.load('../train/audio/_background_noise_/doing_the_dishes.wav', sr=sr)[0].tolist()\n",
    "UNCOLORED_NOISES += librosa.load('../train/audio/_background_noise_/dude_miaowing.wav', sr=sr)[0].tolist()\n",
    "UNCOLORED_NOISES += librosa.load('../train/audio/_background_noise_/exercise_bike.wav', sr=sr)[0].tolist()\n",
    "UNCOLORED_NOISES += librosa.load('../train/audio/_background_noise_/running_tap.wav', sr=sr)[0].tolist()\n",
    "\n",
    "\n",
    "def get_silence():\n",
    "    choice = np.random.choice([0, 1, 2, 4], p=[0.01, 0.10, 0.30, 0.59])\n",
    "    if choice == 0:\n",
    "        return np.zeros((16000))\n",
    "    elif choice == 1:\n",
    "        idx = random.randint(0, len(UNCOLORED_NOISES) - sr)\n",
    "        return np.array(UNCOLORED_NOISES[idx:idx+sr], dtype=np.float32)\n",
    "    elif choice == 3:\n",
    "        return np.array(acoustics.generator.noise(16000, color=np.random.choice(['pink', 'white']))/3, np.float32)\n",
    "    else:\n",
    "        random_silence_file = np.random.choice(LABEL_TO_FILE_NAMES['silence'])\n",
    "        return file_to_sample(random_silence_file)\n",
    "\n",
    "def pad_zeros(samples):\n",
    "    if len(samples) < sr:\n",
    "        diff = sr - len(samples)\n",
    "        diff_div = diff // 2\n",
    "        samples = np.lib.pad(samples, (diff_div, diff - diff_div), 'constant', constant_values = (0, 0))\n",
    "    return samples\n",
    "\n",
    "def pitch_shift(samples, sr=sr):\n",
    "    return librosa.effects.pitch_shift(samples, sr=sr, n_steps=random.randint(1, 5))\n",
    "\n",
    "def get_shuffled_XY(X, Y):\n",
    "    m = X.shape[0]\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "    return shuffled_X, shuffled_Y\n",
    "\n",
    "def time_shift(arr):\n",
    "    num = np.random.uniform(0, 0.03) * len(arr)\n",
    "    num = int(num)\n",
    "    result = np.empty_like(arr)\n",
    "    if num > 0:\n",
    "        result[:num] = 0\n",
    "        result[num:] = arr[:-num]\n",
    "    elif num < 0:\n",
    "        result[num:] = 0\n",
    "        result[:num] = arr[-num:]\n",
    "    else:\n",
    "        result = arr\n",
    "    return np.array(result)\n",
    "        \n",
    "def flip_transform(wave):\n",
    "    if np.random.choice([0, 1]):\n",
    "        return -wave\n",
    "\n",
    "def noise_mix(wave):\n",
    "    if np.random.random() < 0.40:\n",
    "        return wave\n",
    "    noise = get_silence()\n",
    "    noise_limit = random.uniform(0, 0.1)\n",
    "    wave = (1 - noise_limit) * wave + noise_limit * noise\n",
    "    return wave\n",
    "\n",
    "# 72 * 72\n",
    "def get_melspectrogram(samples):\n",
    "    S = librosa.feature.melspectrogram(samples, sr=sr, n_mels=72, hop_length=223, n_fft=512)\n",
    "    spec = librosa.power_to_db(S, ref=np.max)\n",
    "    spec = np.repeat(spec[np.newaxis,:,:,np.newaxis], 3, axis=3)\n",
    "    return spec\n",
    "\n",
    "# 150 * 150\n",
    "def get_mel_of_150_150(samples):\n",
    "    S = librosa.feature.melspectrogram(samples, sr=sr, n_mels=150, hop_length=107, n_fft=512)\n",
    "    spec = librosa.power_to_db(S, ref=np.max)\n",
    "    spec = np.repeat(spec[np.newaxis,:,:,np.newaxis], 3, axis=3)\n",
    "    return spec\n",
    "\n",
    "# 197 * 161\n",
    "def log_specgram(audio, sample_rate=16000, window_size=20,\n",
    "                 step_size=15, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    spec = np.log(spec.T.astype(np.float32) + eps)\n",
    "    return np.repeat(spec[np.newaxis,:,:,np.newaxis], 3, axis=3)\n",
    "\n",
    "def get_transformed_samples(samples):\n",
    "    samples = pad_zeros(samples)\n",
    "    samples = time_shift(samples)\n",
    "    samples = noise_mix(samples)\n",
    "    if np.random.choice([0, 1]):\n",
    "        samples = -samples\n",
    "    stdx = np.std(samples)\n",
    "    if stdx:\n",
    "        sampels = samples / stdx\n",
    "    #samples = flip_transform(samples)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'silence', 'unknown']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing train label to filename lengths\n",
      "right 6811\n",
      "go 5331\n",
      "unknown 70315\n",
      "off 6456\n",
      "yes 6221\n",
      "stop 6733\n",
      "down 5355\n",
      "left 6552\n",
      "no 6248\n",
      "silence 6591\n",
      "on 6561\n",
      "up 5944\n",
      "printing validation label to filename lengths\n",
      "right 756\n",
      "go 592\n",
      "unknown 7812\n",
      "off 717\n",
      "yes 691\n",
      "stop 748\n",
      "down 594\n",
      "left 728\n",
      "no 694\n",
      "silence 732\n",
      "on 729\n",
      "up 660\n"
     ]
    }
   ],
   "source": [
    "print('printing train label to filename lengths')\n",
    "for label, filenames in TRAIN_LABEL_TO_FILE_NAMES.items():\n",
    "    print(label, len(filenames))\n",
    "print('printing validation label to filename lengths')\n",
    "for label, filenames in VALIDATION_LABEL_TO_FILE_NAMES.items():\n",
    "    print(label, len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " overall_time: 0m8s time_from_previous_call: 0m8s\n"
     ]
    }
   ],
   "source": [
    "print(time_taken())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "def validation_data_generator():\n",
    "    XV = np.zeros((batch_size, 150, 150, 3))\n",
    "    YV = np.zeros((batch_size, num_classes))\n",
    "    while True:\n",
    "        for idx in range(batch_size):\n",
    "            random_label = np.random.choice(labels)\n",
    "            if random_label == 'silence':\n",
    "                samples = get_silence()\n",
    "            else:\n",
    "                random_filename = np.random.choice(VALIDATION_LABEL_TO_FILE_NAMES[random_label])\n",
    "                samples = file_to_sample(random_filename)\n",
    "                samples = get_transformed_samples(samples)\n",
    "            spec = get_mel_of_150_150(samples)\n",
    "            XV[idx, :, :] = spec\n",
    "            this_Y = [labels.index(random_label)]\n",
    "            this_Y = keras.utils.to_categorical(np.array(this_Y).astype(np.float32), num_classes)\n",
    "            YV[idx, :] = this_Y\n",
    "        yield XV, YV\n",
    "\n",
    "def train_data_generator():\n",
    "    XT = np.zeros((batch_size, 150, 150, 3))\n",
    "    YT = np.zeros((batch_size, num_classes))\n",
    "    while True:\n",
    "        for idx in range(batch_size):\n",
    "            random_label = np.random.choice(labels)\n",
    "            if random_label == 'silence':\n",
    "                samples = get_silence()\n",
    "            else:\n",
    "                random_filename = np.random.choice(TRAIN_LABEL_TO_FILE_NAMES[random_label])\n",
    "                samples = file_to_sample(random_filename)\n",
    "                samples = get_transformed_samples(samples)\n",
    "            spec = get_mel_of_150_150(samples)\n",
    "            XT[idx, :, :] = spec\n",
    "            this_Y = [labels.index(random_label)]\n",
    "            this_Y = keras.utils.to_categorical(np.array(this_Y).astype(np.float32), num_classes)\n",
    "            YT[idx, :] = this_Y\n",
    "        yield XT, YT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.5832 - acc: 0.8174Epoch 00001: val_acc improved from -inf to 0.08633, saving model to model-pseudo-88-data-aug-melspec-inception-resnet-v2-0-01-0.0863-2.4865.h5\n",
      "200/200 [==============================] - 350s 2s/step - loss: 0.5823 - acc: 0.8179 - val_loss: 2.4865 - val_acc: 0.0863\n",
      "Epoch 2/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.2243 - acc: 0.9398Epoch 00002: val_acc did not improve\n",
      "200/200 [==============================] - 317s 2s/step - loss: 0.2245 - acc: 0.9400 - val_loss: 2.9882 - val_acc: 0.0809\n",
      "Epoch 3/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1950 - acc: 0.9497Epoch 00003: val_acc improved from 0.08633 to 0.85664, saving model to model-pseudo-88-data-aug-melspec-inception-resnet-v2-0-03-0.8566-0.5058.h5\n",
      "200/200 [==============================] - 317s 2s/step - loss: 0.1948 - acc: 0.9497 - val_loss: 0.5058 - val_acc: 0.8566\n",
      "Epoch 4/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1607 - acc: 0.9588Epoch 00004: val_acc improved from 0.85664 to 0.91563, saving model to model-pseudo-88-data-aug-melspec-inception-resnet-v2-0-04-0.9156-0.3417.h5\n",
      "200/200 [==============================] - 317s 2s/step - loss: 0.1608 - acc: 0.9589 - val_loss: 0.3417 - val_acc: 0.9156\n",
      "Epoch 5/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1684 - acc: 0.9620Epoch 00005: val_acc did not improve\n",
      "200/200 [==============================] - 319s 2s/step - loss: 0.1688 - acc: 0.9620 - val_loss: 0.6442 - val_acc: 0.8625\n",
      "Epoch 6/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1573 - acc: 0.9657Epoch 00006: val_acc improved from 0.91563 to 0.93203, saving model to model-pseudo-88-data-aug-melspec-inception-resnet-v2-0-06-0.9320-0.3107.h5\n",
      "200/200 [==============================] - 319s 2s/step - loss: 0.1577 - acc: 0.9656 - val_loss: 0.3107 - val_acc: 0.9320\n",
      "Epoch 7/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1583 - acc: 0.9663Epoch 00007: val_acc improved from 0.93203 to 0.95469, saving model to model-pseudo-88-data-aug-melspec-inception-resnet-v2-0-07-0.9547-0.2141.h5\n",
      "200/200 [==============================] - 316s 2s/step - loss: 0.1583 - acc: 0.9663 - val_loss: 0.2141 - val_acc: 0.9547\n",
      "Epoch 8/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1520 - acc: 0.9692Epoch 00008: val_acc did not improve\n",
      "200/200 [==============================] - 316s 2s/step - loss: 0.1516 - acc: 0.9692 - val_loss: 0.2933 - val_acc: 0.9195\n",
      "Epoch 9/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1463 - acc: 0.9720Epoch 00009: val_acc improved from 0.95469 to 0.96367, saving model to model-pseudo-88-data-aug-melspec-inception-resnet-v2-0-09-0.9637-0.1849.h5\n",
      "200/200 [==============================] - 316s 2s/step - loss: 0.1458 - acc: 0.9720 - val_loss: 0.1849 - val_acc: 0.9637\n",
      "Epoch 10/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1396 - acc: 0.9715Epoch 00010: val_acc did not improve\n",
      "200/200 [==============================] - 319s 2s/step - loss: 0.1394 - acc: 0.9714 - val_loss: 0.2060 - val_acc: 0.9539\n",
      "Epoch 11/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1288 - acc: 0.9757Epoch 00011: val_acc did not improve\n",
      "200/200 [==============================] - 316s 2s/step - loss: 0.1286 - acc: 0.9757 - val_loss: 0.2719 - val_acc: 0.9395\n",
      "Epoch 12/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1331 - acc: 0.9741Epoch 00012: val_acc did not improve\n",
      "200/200 [==============================] - 316s 2s/step - loss: 0.1328 - acc: 0.9742 - val_loss: 0.3339 - val_acc: 0.9070\n",
      "Epoch 13/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1249 - acc: 0.9757Epoch 00013: val_acc did not improve\n",
      "200/200 [==============================] - 315s 2s/step - loss: 0.1261 - acc: 0.9756 - val_loss: 0.2006 - val_acc: 0.9613\n",
      "Epoch 14/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.1157 - acc: 0.9784Epoch 00014: val_acc did not improve\n",
      "\n",
      "Epoch 00014: reducing learning rate to 0.00020000000949949026.\n",
      "200/200 [==============================] - 315s 2s/step - loss: 0.1159 - acc: 0.9785 - val_loss: 0.2333 - val_acc: 0.9480\n",
      "Epoch 15/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0936 - acc: 0.9843Epoch 00015: val_acc improved from 0.96367 to 0.97891, saving model to model-pseudo-88-data-aug-melspec-inception-resnet-v2-0-15-0.9789-0.1244.h5\n",
      "200/200 [==============================] - 315s 2s/step - loss: 0.0941 - acc: 0.9843 - val_loss: 0.1244 - val_acc: 0.9789\n",
      "Epoch 16/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0930 - acc: 0.9853Epoch 00016: val_acc improved from 0.97891 to 0.97930, saving model to model-pseudo-88-data-aug-melspec-inception-resnet-v2-0-16-0.9793-0.1137.h5\n",
      "200/200 [==============================] - 313s 2s/step - loss: 0.0931 - acc: 0.9853 - val_loss: 0.1137 - val_acc: 0.9793\n",
      "Epoch 17/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0845 - acc: 0.9873Epoch 00017: val_acc did not improve\n",
      "200/200 [==============================] - 316s 2s/step - loss: 0.0852 - acc: 0.9873 - val_loss: 0.1463 - val_acc: 0.9734\n",
      "Epoch 18/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0839 - acc: 0.9870Epoch 00018: val_acc did not improve\n",
      "200/200 [==============================] - 314s 2s/step - loss: 0.0836 - acc: 0.9871 - val_loss: 0.1410 - val_acc: 0.9766\n",
      "Epoch 19/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0749 - acc: 0.9891Epoch 00019: val_acc did not improve\n",
      "200/200 [==============================] - 314s 2s/step - loss: 0.0754 - acc: 0.9890 - val_loss: 0.1252 - val_acc: 0.9762\n",
      "Epoch 20/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0801 - acc: 0.9885Epoch 00020: val_acc did not improve\n",
      "200/200 [==============================] - 315s 2s/step - loss: 0.0805 - acc: 0.9885 - val_loss: 0.1279 - val_acc: 0.9758\n",
      "Epoch 21/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0836 - acc: 0.9875Epoch 00021: val_acc did not improve\n",
      "\n",
      "Epoch 00021: reducing learning rate to 4.0000001899898055e-05.\n",
      "200/200 [==============================] - 316s 2s/step - loss: 0.0832 - acc: 0.9876 - val_loss: 0.1556 - val_acc: 0.9734\n",
      "Epoch 22/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0778 - acc: 0.9891Epoch 00022: val_acc improved from 0.97930 to 0.98086, saving model to model-pseudo-88-data-aug-melspec-inception-resnet-v2-0-22-0.9809-0.1052.h5\n",
      "200/200 [==============================] - 314s 2s/step - loss: 0.0778 - acc: 0.9891 - val_loss: 0.1052 - val_acc: 0.9809\n",
      "Epoch 23/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0743 - acc: 0.9895Epoch 00023: val_acc did not improve\n",
      "200/200 [==============================] - 313s 2s/step - loss: 0.0743 - acc: 0.9895 - val_loss: 0.1073 - val_acc: 0.9805\n",
      "Epoch 24/200\n",
      "157/200 [======================>.......] - ETA: 57s - loss: 0.0707 - acc: 0.9902"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "model = keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=True, weights=None, input_tensor=None, input_shape=None, pooling=None, classes=num_classes)\n",
    "model = keras.applications.xception.Xception(include_top=True, weights=None, input_tensor=None, input_shape=None, pooling=None, classes=num_classes)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "#model = load_model('model-pseudo-88-melspec-inception-resnet-v2-1-08-0.99-0.04.h5')\n",
    "checkpoint = ModelCheckpoint('model-pseudo-88-data-aug-melspec-inception-resnet-v2-0-{epoch:02d}-{val_acc:.4f}-{val_loss:.4f}.h5',\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             mode='max')\n",
    "earlystopping = EarlyStopping(monitor='val_acc', patience=5)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=1e-8, verbose=1)\n",
    "callback_list = [checkpoint, reduce_lr]\n",
    "\n",
    "train_generator = train_data_generator()\n",
    "validation_generator = validation_data_generator()\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=200, \n",
    "                    epochs=epochs, \n",
    "                    callbacks=callback_list,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=20,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time_taken())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
