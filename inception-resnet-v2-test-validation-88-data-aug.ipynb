{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np # linear algebra\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, Convolution2D, Activation\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import os\n",
    "import random\n",
    "from scipy.io import wavfile\n",
    "from subprocess import check_output\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import acoustics\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import random\n",
    "\n",
    "def timer():\n",
    "    time_start = [int(time.time())]\n",
    "    time_start_overall = [int(time.time())]\n",
    "\n",
    "    def time_taken():\n",
    "        time_now = int(time.time())\n",
    "        om, os = divmod(time_now - time_start_overall[0], 60)\n",
    "        m, s = divmod(time_now - time_start[0], 60)\n",
    "        time_start[0] = time_now\n",
    "        return ' overall_time: ' + str(om) + 'm' + str(os) + 's' + ' time_from_previous_call: ' + str(m) + 'm' + str(s) + 's'\n",
    "    return time_taken\n",
    "time_taken = timer()\n",
    "\n",
    "sr = 16000\n",
    "\n",
    "unknowns = 'bed bird cat dog eight five four happy house marvin nine one seven sheila six three tree two wow zero'.split()\n",
    "knowns = 'yes no up down left right on off stop go'.split()\n",
    "silence = 'silence'.split()\n",
    "labels = knowns + silence + ['unknown'] \n",
    "num_classes = len(labels)\n",
    "\n",
    "LABEL_TO_FILE_NAMES = {}\n",
    "VALIDATION_LABEL_TO_FILE_NAMES = {}\n",
    "TRAIN_LABEL_TO_FILE_NAMES = {}\n",
    "FILE_TO_LABEL = {}\n",
    "with open('train-88.csv') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        line = line.split(',')\n",
    "        LABEL_TO_FILE_NAMES.setdefault(line[1], [])\n",
    "        LABEL_TO_FILE_NAMES[line[1]].append(line[0])\n",
    "        TRAIN_LABEL_TO_FILE_NAMES.setdefault(line[1], [])\n",
    "        TRAIN_LABEL_TO_FILE_NAMES[line[1]].append(line[0])\n",
    "        FILE_TO_LABEL[line[0]] = line[1]\n",
    "with open('validation-88.csv') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        line = line.split(',')\n",
    "        LABEL_TO_FILE_NAMES.setdefault(line[1], [])\n",
    "        LABEL_TO_FILE_NAMES[line[1]].append(line[0])\n",
    "        VALIDATION_LABEL_TO_FILE_NAMES.setdefault(line[1], [])\n",
    "        VALIDATION_LABEL_TO_FILE_NAMES[line[1]].append(line[0])\n",
    "        FILE_TO_LABEL[line[0]] = line[1]\n",
    "\n",
    "\n",
    "def file_to_sample(filename):\n",
    "    samples, _ = librosa.load(filename, sr=sr)\n",
    "    return samples\n",
    "    \n",
    "\n",
    "UNCOLORED_NOISES = []\n",
    "UNCOLORED_NOISES += librosa.load('../train/audio/_background_noise_/doing_the_dishes.wav', sr=sr)[0].tolist()\n",
    "UNCOLORED_NOISES += librosa.load('../train/audio/_background_noise_/dude_miaowing.wav', sr=sr)[0].tolist()\n",
    "UNCOLORED_NOISES += librosa.load('../train/audio/_background_noise_/exercise_bike.wav', sr=sr)[0].tolist()\n",
    "UNCOLORED_NOISES += librosa.load('../train/audio/_background_noise_/running_tap.wav', sr=sr)[0].tolist()\n",
    "\n",
    "\n",
    "def get_silence():\n",
    "    choice = np.random.choice([0, 1, 2, 4], p=[0.01, 0.10, 0.60, 0.29])\n",
    "    if choice == 0:\n",
    "        return np.zeros((16000))\n",
    "    elif choice == 1:\n",
    "        idx = random.randint(0, len(UNCOLORED_NOISES) - sr)\n",
    "        return np.array(UNCOLORED_NOISES[idx:idx+sr], dtype=np.float32)\n",
    "    elif choice == 3:\n",
    "        return np.array(acoustics.generator.noise(16000, color=np.random.choice(['pink', 'white']))/3, np.float32)\n",
    "    else:\n",
    "        random_silence_file = np.random.choice(LABEL_TO_FILE_NAMES['silence'])\n",
    "        return file_to_sample(random_silence_file)\n",
    "\n",
    "def pad_zeros(samples):\n",
    "    if len(samples) < sr:\n",
    "        diff = sr - len(samples)\n",
    "        diff_div = diff // 2\n",
    "        samples = np.lib.pad(samples, (diff_div, diff - diff_div), 'constant', constant_values = (0, 0))\n",
    "    return samples\n",
    "\n",
    "def pitch_shift(samples, sr=sr):\n",
    "    return librosa.effects.pitch_shift(samples, sr=sr, n_steps=random.randint(1, 5))\n",
    "\n",
    "def get_shuffled_XY(X, Y):\n",
    "    m = X.shape[0]\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "    return shuffled_X, shuffled_Y\n",
    "\n",
    "def time_shift(arr):\n",
    "    num = np.random.uniform(0, 0.2) * len(arr)\n",
    "    num = int(num)\n",
    "    result = np.empty_like(arr)\n",
    "    if num > 0:\n",
    "        result[:num] = 0\n",
    "        result[num:] = arr[:-num]\n",
    "    elif num < 0:\n",
    "        result[num:] = 0\n",
    "        result[:num] = arr[-num:]\n",
    "    else:\n",
    "        result = arr\n",
    "    return np.array(result)\n",
    "        \n",
    "def flip_transform(wave):\n",
    "    if np.random.choice([0, 1]):\n",
    "        return -wave\n",
    "\n",
    "def noise_mix(wave):\n",
    "    if np.random.random() < 0.10:\n",
    "        return wave\n",
    "    noise = get_silence()\n",
    "    noise_limit = random.uniform(0, 0.1)\n",
    "    wave = (1 - noise_limit) * wave + noise_limit * noise\n",
    "    return wave\n",
    "\n",
    "# 72 * 72\n",
    "def get_melspectrogram(samples):\n",
    "    S = librosa.feature.melspectrogram(samples, sr=sr, n_mels=72, hop_length=223, n_fft=512)\n",
    "    spec = librosa.power_to_db(S, ref=np.max)\n",
    "    spec = np.repeat(spec[np.newaxis,:,:,np.newaxis], 3, axis=3)\n",
    "    return spec\n",
    "\n",
    "# 150 * 150\n",
    "def get_mel_of_150_150(samples):\n",
    "    S = librosa.feature.melspectrogram(samples, sr=sr, n_mels=150, hop_length=107, n_fft=512)\n",
    "    spec = librosa.power_to_db(S, ref=np.max)\n",
    "    spec = np.repeat(spec[np.newaxis,:,:,np.newaxis], 3, axis=3)\n",
    "    return spec\n",
    "\n",
    "# 197 * 161\n",
    "def log_specgram(audio, sample_rate=16000, window_size=20,\n",
    "                 step_size=15, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    spec = np.log(spec.T.astype(np.float32) + eps)\n",
    "    return np.repeat(spec[np.newaxis,:,:,np.newaxis], 3, axis=3)\n",
    "\n",
    "def get_transformed_samples(samples):\n",
    "    samples = pad_zeros(samples)\n",
    "    samples = time_shift(samples)\n",
    "    samples = noise_mix(samples)\n",
    "    if np.random.choice([0, 1]):\n",
    "        samples = -samples\n",
    "    stdx = np.std(samples)\n",
    "    if stdx:\n",
    "        sampels = samples / stdx\n",
    "    #samples = flip_transform(samples)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'silence', 'unknown']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing train label to filename lengths\n",
      "stop 6733\n",
      "unknown 70315\n",
      "down 5355\n",
      "on 6561\n",
      "left 6552\n",
      "right 6811\n",
      "go 5331\n",
      "no 6248\n",
      "yes 6221\n",
      "off 6456\n",
      "up 5944\n",
      "silence 6591\n",
      "printing validation label to filename lengths\n",
      "stop 748\n",
      "unknown 7812\n",
      "down 594\n",
      "on 729\n",
      "left 728\n",
      "right 756\n",
      "go 592\n",
      "no 694\n",
      "yes 691\n",
      "off 717\n",
      "up 660\n",
      "silence 732\n"
     ]
    }
   ],
   "source": [
    "print('printing train label to filename lengths')\n",
    "for label, filenames in TRAIN_LABEL_TO_FILE_NAMES.items():\n",
    "    print(label, len(filenames))\n",
    "print('printing validation label to filename lengths')\n",
    "for label, filenames in VALIDATION_LABEL_TO_FILE_NAMES.items():\n",
    "    print(label, len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " overall_time: 0m14s time_from_previous_call: 0m14s\n"
     ]
    }
   ],
   "source": [
    "print(time_taken())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "def validation_data_generator():\n",
    "    XV = np.zeros((batch_size, 150, 150, 3))\n",
    "    YV = np.zeros((batch_size, num_classes))\n",
    "    while True:\n",
    "        for idx in range(batch_size):\n",
    "            random_label = np.random.choice(labels)\n",
    "            if random_label == 'silence':\n",
    "                samples = get_silence()\n",
    "            else:\n",
    "                random_filename = np.random.choice(VALIDATION_LABEL_TO_FILE_NAMES[random_label])\n",
    "                samples = file_to_sample(random_filename)\n",
    "                samples = get_transformed_samples(samples)\n",
    "            spec = get_mel_of_150_150(samples)\n",
    "            XV[idx, :, :] = spec\n",
    "            this_Y = [labels.index(random_label)]\n",
    "            this_Y = keras.utils.to_categorical(np.array(this_Y).astype(np.float32), num_classes)\n",
    "            YV[idx, :] = this_Y\n",
    "        yield XV, YV\n",
    "\n",
    "def train_data_generator():\n",
    "    XT = np.zeros((batch_size, 150, 150, 3))\n",
    "    YT = np.zeros((batch_size, num_classes))\n",
    "    while True:\n",
    "        for idx in range(batch_size):\n",
    "            random_label = np.random.choice(labels)\n",
    "            if random_label == 'silence':\n",
    "                samples = get_silence()\n",
    "            else:\n",
    "                random_filename = np.random.choice(TRAIN_LABEL_TO_FILE_NAMES[random_label])\n",
    "                samples = file_to_sample(random_filename)\n",
    "                samples = get_transformed_samples(samples)\n",
    "            spec = get_mel_of_150_150(samples)\n",
    "            XT[idx, :, :] = spec\n",
    "            this_Y = [labels.index(random_label)]\n",
    "            this_Y = keras.utils.to_categorical(np.array(this_Y).astype(np.float32), num_classes)\n",
    "            YT[idx, :] = this_Y\n",
    "        yield XT, YT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0550 - acc: 0.9910Epoch 00001: val_acc improved from -inf to 0.98750, saving model to model-pseudo-88-melspec-inception-resnet-v2-1-01-0.99-0.05.h5\n",
      "200/200 [==============================] - 519s 3s/step - loss: 0.0549 - acc: 0.9911 - val_loss: 0.0530 - val_acc: 0.9875\n",
      "Epoch 2/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0531 - acc: 0.9909Epoch 00002: val_acc did not improve\n",
      "200/200 [==============================] - 323s 2s/step - loss: 0.0530 - acc: 0.9909 - val_loss: 0.0703 - val_acc: 0.9840\n",
      "Epoch 3/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0484 - acc: 0.9920Epoch 00003: val_acc did not improve\n",
      "200/200 [==============================] - 323s 2s/step - loss: 0.0485 - acc: 0.9920 - val_loss: 0.0719 - val_acc: 0.9824\n",
      "Epoch 4/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0541 - acc: 0.9906Epoch 00004: val_acc improved from 0.98750 to 0.98945, saving model to model-pseudo-88-melspec-inception-resnet-v2-1-04-0.99-0.05.h5\n",
      "200/200 [==============================] - 323s 2s/step - loss: 0.0543 - acc: 0.9906 - val_loss: 0.0518 - val_acc: 0.9895\n",
      "Epoch 5/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0571 - acc: 0.9898Epoch 00005: val_acc did not improve\n",
      "200/200 [==============================] - 320s 2s/step - loss: 0.0568 - acc: 0.9898 - val_loss: 0.0588 - val_acc: 0.9887\n",
      "Epoch 6/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0499 - acc: 0.9914Epoch 00006: val_acc did not improve\n",
      "200/200 [==============================] - 317s 2s/step - loss: 0.0497 - acc: 0.9914 - val_loss: 0.0617 - val_acc: 0.9871\n",
      "Epoch 7/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0545 - acc: 0.9905Epoch 00007: val_acc did not improve\n",
      "200/200 [==============================] - 322s 2s/step - loss: 0.0545 - acc: 0.9905 - val_loss: 0.0607 - val_acc: 0.9848\n",
      "Epoch 8/200\n",
      "199/200 [============================>.] - ETA: 1s - loss: 0.0477 - acc: 0.9921Epoch 00008: val_acc improved from 0.98945 to 0.99062, saving model to model-pseudo-88-melspec-inception-resnet-v2-1-08-0.99-0.04.h5\n",
      "200/200 [==============================] - 319s 2s/step - loss: 0.0479 - acc: 0.9921 - val_loss: 0.0447 - val_acc: 0.9906\n",
      "Epoch 9/200\n",
      " 24/200 [==>...........................] - ETA: 2:42 - loss: 0.0427 - acc: 0.9928"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "#model = keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=True, weights=None, input_tensor=None, input_shape=None, pooling=None, classes=num_classes)\n",
    "#model = keras.applications.xception.Xception(include_top=True, weights=None, input_tensor=None, input_shape=None, pooling=None, classes=num_classes)\n",
    "# model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#               optimizer=keras.optimizers.Adam(),\n",
    "#               metrics=['accuracy'])\n",
    "model = load_model('model-pseudo-88-melspec-inception-resnet-v2-0-114-0.99-0.07.h5')\n",
    "checkpoint = ModelCheckpoint('model-pseudo-88-melspec-inception-resnet-v2-1-{epoch:02d}-{val_acc:.2f}-{val_loss:.2f}.h5',\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             mode='max')\n",
    "earlystopping = EarlyStopping(monitor='val_acc', patience=5)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=1e-8, verbose=1)\n",
    "callback_list = [checkpoint, reduce_lr]\n",
    "\n",
    "train_generator = train_data_generator()\n",
    "validation_generator = validation_data_generator()\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=200, \n",
    "                    epochs=epochs, \n",
    "                    callbacks=callback_list,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=20,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time_taken())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
